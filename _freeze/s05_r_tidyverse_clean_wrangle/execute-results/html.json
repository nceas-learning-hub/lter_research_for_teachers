{
  "hash": "673f04bf58fdd680ed15aa01c4783353",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Cleaning and Wrangling Data\n---\n\n\n\n\n:::{.callout-tip}\n## Learning Objectives\n- Introduce `dplyr` and `tidyr` functions to clean and wrangle data for analysis\n- Learn about the Split-Apply-Combine strategy and how it applies to data wrangling\n- Describe the difference between wide vs. long table formats and how to convert between them\n:::\n\n\n## Introduction\n\nThe data we get to work with are rarely, if ever, in the format we need to do our analyses. \nIt’s often the case that one package requires data in one format, while another package requires the data to be in another format. \nTo be efficient analysts, we should have good tools for reformatting data for our needs so we can do further work like making plots and fitting models.\nThe `dplyr` and `tidyr` R packages provide a fairly complete and extremely powerful set of functions for us to do this reformatting quickly. \nLearning these tools well will greatly increase your efficiency as an analyst.\n\nLet's look at two motivating examples. \n\n::: {.callout-note appearance=\"minimal\" icon=false}\n## Example 1\nSuppose you have the following `data.frame` called `length_data` with data about salmon length and want to calculate the average length per year. \n\n|  year|  length\\_cm|\n|-----:|-----------:|\n|  1990|    5.673318|\n|  1991|    3.081224|\n|  1991|    4.592696|\n|  1992|    4.381523|\n|  1992|    5.597777|\n|  1992|    4.900052|\n\nBefore thinking about the code, let's think about the steps we need to take to get to the answer (aka pseudocode).\n\nNow, how would we code this? The `dplyr` R library provides a fast and powerful way to do this calculation in a few lines of code:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Answer\"}\nlength_data %>% \n  group_by(year) %>% \n  summarize(mean_length_cm = mean(length_cm))\n```\n:::\n\n\n\n:::\n\n\n::: {.callout-note appearance=\"minimal\" icon=false}\n## Example 2\n Another process we often need to do is to \"reshape\" our data. Consider the following table that is in what we call \"wide\" format:\n\n| site   | 1990 | 1991 | ... | 1993 |\n|--------|------|------|-----|------|\n| gold   | 100  | 118  | ... | 112  |\n| lake   | 100  | 118  | ... | 112  |\n| ...    | ...  | ...  | ... | ...  |\n| dredge | 100  | 118  | ... | 112  |\n\nYou are probably familiar with data in the above format, where values of the variable being observed are spread out across columns. \nIn this example we have a different column per year. \nThis wide format works well for data entry and sometimes works well for analysis but we quickly outgrow it when using R (and know it is not tidy data!). \nFor example, how would you fit a model with year as a predictor variable? In an ideal world, we'd be able to just run `lm(length ~ year)`.\nBut this won't work on our wide data because `lm()` needs `length` and `year` to be columns in our table.\n\nWhat steps would you take to get this data frame in a long format?\n\nThe `tidyr` package allows us to quickly switch between wide format and long format using the `pivot_longer()` function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Answer\"}\nsite_data %>% \n  pivot_longer(-site, \n               names_to = \"year\", \n               values_to = \"length\")\n```\n:::\n\n\n\n\n| site   | year |  length|\n|--------|------|-------:|\n| gold   | 1990 |     101|\n| lake   | 1990 |     104|\n| dredge | 1990 |     144|\n| ...    | ...  |     ...|\n| dredge | 1993 |     145|\n:::\n\nThis lesson will cover examples to learn about the functions you'll most commonly use from the `dplyr` and `tidyr` packages:\n\n| Function name   | Description |\n|--------|------|\n| `mutate()`  | Creates modify and deletes columns |   \n| `group_by()`  | Groups data by one or more variables |\n| `summarise()` | Summaries each group down to one row |\n|  `select()` | Keep or drop columns using their names  |\n| `filter()`  | Keeps rows that matches conditions |\n| `arrange()`  | order rows using columns variable |\n| `rename()`  | Rename a column |\n\n: Common `dplyr` functions {tbl-colwidths=\"[25,75]\"}\n\n\n| Function name   | Description |\n|--------|------|\n| `pivot_longer()`  | transforms data from a wide to a long format |   \n| `pivot_wider()`  | transforms data from a long to a wide format |\n| `unite()` | Unite multiple columns into one by pasting strings together |\n|  `separate()` | Separate a character column into multiple columns with a regular expression or numeric locations |\n\n: Common `tidyr` functions {tbl-colwidths=\"[25,75]\"}\n\n## Data cleaning basics\n\nTo demonstrate, we'll be working with a tidied up version of a data set from [Alaska Department of Fish & Game containing commercial catch data from 1878-1997](https://knb.ecoinformatics.org/#view/df35b.304.2). The data set and reference to the original source can be found at its [public archive](https://knb.ecoinformatics.org/#view/df35b.304.2).\n\n::: {.callout-tip icon=false}\n## Setup\nFirst, open a new Quarto document. Delete everything below the setup chunk, and add a library chunk that calls `dplyr`, `tidyr`, and `readr`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\n```\n:::\n\n\n\n\n:::\n\n::: {.callout-important}\n\n### A note on loading packages\n\nYou may have noticed the following messages pop up when you ran your library chunk.\n\n```\nAttaching package: ‘dplyr’\n\nThe following objects are masked from ‘package:stats’:\n\n    filter, lag\n\nThe following objects are masked from ‘package:base’:\n\n    intersect, setdiff, setequal, union\n```\n\nThese are important messages. They are letting you know that certain functions from the `stats` and `base` packages (which are loaded by default when you start R) are masked by *different functions* with the same name in the `dplyr` package. It turns out, the order that you load the packages in matters. Since we loaded `dplyr` after `stats`, R will assume that if you call `filter()`, you mean the `dplyr` version unless you specify otherwise.\n\nBeing specific about which version of `filter()`, for example, you call is easy. \nTo explicitly call a function by its unambiguous name, we use the syntax `package_name::function_name(...)`. \nSo, if we wanted to call the `stats` version of `filter()` in this Rmarkdown document, I would use the syntax `stats::filter(...)`.\n:::\n\n\n\n::: {.callout-caution icon=false}\n### Remove messages and warnings\n\nMessages and warnings are important, but we might not want them in our final document. After you have read the packages in, **adjust the chunk settings in your library chunk** to suppress warnings and messages by adding `#| message: false` or `#| warning: false`. Both of these chunk options, when set to false, prevents messages or warnings from appearing in the rendered file.\n:::\n\nNow that we have introduced some data wrangling libraries, let's get the data that we are going to use for this lesson.\n\n::: {.callout-tip icon=false}\n## Setup\n\n1. Go to [KNB Data Package Alaska commercial salmon catches by management region (1886- 1997)](https://knb.ecoinformatics.org/view/df35b.304.2)\n\n2. Find the data file `df35b.302.1`. Right click the \"Download\" button and select \"Copy Link Address\"\n\n3. Paste the copied URL into the `read_csv()` function\n\nThe code chunk you use to read in the data should look something like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_original <- read_csv(\"https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1\")\n```\n:::\n\n\n\n\n**Note for Windows users:** Keep in mind, if you want to replicate this workflow in your local computer you also need to use the `url()` function here with the argument `method = \"libcurl\"`. \n\nIt would look like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_original <- read.csv(url(\"https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1\", method = \"libcurl\"))\n```\n:::\n\n\n\n\n:::\n\nThis data set is relatively clean and easy to interpret as-is. While it may be clean, it's in a shape that makes it hard to use for some types of analyses so we'll want to fix that first.\n\n::: {.callout-note icon=false}\n## Exercise\n\nBefore we get too much further, spend a minute or two outlining your Quarto document so that it includes the following sections and steps:\n\n- Data Sources\n  - Read in the data\n  - Explore data\n- Clean and Reshape data\n  - Using `select()` function\n  - Check column types\n  - Replace values in a column with `mutate()`\n  - Reshape data with `pivot_longer()` and `pivot_wider()`\n  - Rename columns `rename()`\n  - Add columns with `mutate()`\n  - Summary stats using `group_by()` and `summarize()`\n  - Filtering rows using `filter()`\n  - Sort data using `arrange()`\n  - Split and combine values in columns with `separate()` and `unite()`\n  \n:::\n\n## Data exploration\nSimilar to what we did in our [Literate Analysis](https://learning.nceas.ucsb.edu/2024-10-coreR/session_05.html) lesson, it is good practice to skim through the data you just read in. \n\nDoing so is important to make sure the data is read as you were expecting and to familiarize yourself with the data.\n\nSome of the basic ways to explore your data are:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Prints the column names of my data frame\ncolnames(catch_original)\n\n## First 6 lines of the data frame\nhead(catch_original)\n\n## Summary of each column of data\nsummary(catch_original)\n\n## Prints unique values in a column (in this case, the region)\nunique(catch_original$Region)\n\n## Opens data frame in its own tab to see each row and column of the data (do in console)\nView(catch_original)\n```\n:::\n\n\n\n\n\n\n## About the pipe (`%>%`) operator\n\nBefore we jump into learning `tidyr` and `dplyr`, we first need to explain the pipeline operator `%>%`.\n\nBoth the `tidyr` and the `dplyr` packages use the pipe operator (`%>%`), which may look unfamiliar. The pipe is a powerful way to efficiently chain together operations. The pipe will take the output of a previous statement, and use it as the input to the next statement.\n\nSay you want to both `filter()` out rows of a data set, and `select()` certain columns.\n\nInstead of writing:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_filtered <- filter(df, ...)\ndf_selected <- select(df_filtered, ...)\n```\n:::\n\n\n\n\nYou can write:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_cleaned <- df %>% \n    filter(...) %>%\n    select(...)\n```\n:::\n\n\n\n\nIf you think of the assignment operator (`<-`) as reading like \"gets\", then the pipe operator would read like \"then\".\n\nSo you might think of the above chunk being translated as:\n\n> The cleaned data frame gets the original data, and then a filter (of the original data), and then a select (of the filtered data).\n\nThe benefits to using pipes are that you don't have to keep track of (or overwrite) intermediate data frames. The drawbacks are that it can be more difficult to explain the reasoning behind each step, especially when many operations are chained together. It is good to strike a balance between writing efficient code (chaining operations), while ensuring that you are still clearly explaining, both to your future self and others, what you are doing and why you are doing it.\n\n::: {.callout-caution icon=false}\n\n## Quick Tip\nRStudio has a keyboard shortcut for `%>%`\n\n- Windows: `Ctrl` + `Shift` + `M` \n- Mac: `cmd` + `shift` + `M`\n:::\n\n## Selecting or removing columns using `select()`\n\nWe're ready to go back to our salmon dataset. \nThe first issue is the extra columns `All` and `notesRegCode`. Let's select only the columns we want, and assign this to a variable called `catch_data`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_data <- catch_original %>%\n    select(Region, Year, Chinook, Sockeye, Coho, Pink, Chum)\n\nhead(catch_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  <chr>  <dbl> <chr>     <dbl> <dbl> <dbl> <dbl>\n1 SSE     1886 0             5     0     0     0\n2 SSE     1887 0           155     0     0     0\n3 SSE     1888 0           224    16     0     0\n4 SSE     1889 0           182    11    92     0\n5 SSE     1890 0           251    42     0     0\n6 SSE     1891 0           274    24     0     0\n```\n\n\n:::\n:::\n\n\n\n\nMuch better!\n\nThe `select()` function also allows you to say which columns you *don't* want, by passing unquoted column names preceded by minus (`-`) signs:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_data <- catch_original %>%\n    select(-All,-notesRegCode)\n```\n:::\n\n\n\n\n## Quality check \n\nNow that we have the data we are interested in using, we should do a little quality check to see that everything seems as expected. \nOne nice way of doing this is the `glimpse()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndplyr::glimpse(catch_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,708\nColumns: 7\n$ Region  <chr> \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\",…\n$ Year    <dbl> 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 18…\n$ Chinook <chr> \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"3\", \"4\", \"5\", \"9…\n$ Sockeye <dbl> 5, 155, 224, 182, 251, 274, 207, 189, 253, 408, 989, 791, 708,…\n$ Coho    <dbl> 0, 0, 16, 11, 42, 24, 11, 1, 5, 8, 192, 161, 132, 139, 84, 107…\n$ Pink    <dbl> 0, 0, 0, 92, 0, 0, 8, 187, 529, 606, 996, 2218, 673, 1545, 204…\n$ Chum    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 1, 2, 0, 0, 0, 102, 343…\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-note icon=false}\n## Exercise\n\nExamine the output of the `glimpse()` function call. Does anything seem amiss with this data set that might warrant fixing?\n\n<details>\n  <summary>**Answer:**</summary>\n  The Chinook catch data are `character` class. Let's fix it using the function `mutate()` before moving on.\n</details>\n:::\n\n## Changing column content using `mutate()`\n\nWe can use the `mutate()` function to change a column, or to create a new column. \nFirst, let's try to convert the Chinook catch values to `numeric` type using the `as.numeric()` function, and overwrite the old Chinook column.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_clean <- catch_data %>%\n    mutate(Chinook = as.numeric(Chinook))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Chinook = as.numeric(Chinook)`.\nCaused by warning:\n! NAs introduced by coercion\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(catch_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  <chr>  <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 SSE     1886       0       5     0     0     0\n2 SSE     1887       0     155     0     0     0\n3 SSE     1888       0     224    16     0     0\n4 SSE     1889       0     182    11    92     0\n5 SSE     1890       0     251    42     0     0\n6 SSE     1891       0     274    24     0     0\n```\n\n\n:::\n:::\n\n\n\n\nWe get a warning ``\"NAs introduced by coercion\"`` which is R telling us that it couldn't convert every value to an integer and, for those values it couldn't convert, it put an `NA` in its place. This is behavior we commonly experience when cleaning data sets and it's important to have the skills to deal with it when it comes up.\n\nTo investigate, let's isolate the issue. We can find out which values are `NA`s with a combination of `is.na()` and `which()`, and save that to a variable called `i`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ni <- which(is.na(catch_clean$Chinook))\ni\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 401\n```\n\n\n:::\n:::\n\n\n\n\nIt looks like there is only one problem row, lets have a look at it in the original data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_data[i,]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  <chr>  <dbl> <chr>     <dbl> <dbl> <dbl> <dbl>\n1 GSE     1955 I            66     0     0     1\n```\n\n\n:::\n:::\n\n\n\n\nWell that's odd: The value in `Chinook` is the letter `I`. It turns out that this data set is from a PDF which was automatically converted into a `csv` and this value of `I` is actually a 1.\n\nLet's fix it by incorporating the `if_else()` function to our `mutate()` call, which will change the value of the `Chinook` column to 1 if the value is equal to `I`, then will use `as.numeric()` to turn the character representations of numbers into numeric typed values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_clean <- catch_data %>%\n    mutate(Chinook = if_else(condition = Chinook == \"I\", \n                             true = \"1\", \n                             false = Chinook),\n           Chinook = as.numeric(Chinook))\n\n##check\ncatch_clean[i, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  <chr>  <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 GSE     1955       1      66     0     0     1\n```\n\n\n:::\n:::\n\n\n\n\n## Changing shape using `pivot_longer()` and `pivot_wider()`\n\nThe next issue is that the data are in a wide format and we want the data in a long format instead. \nThe function `pivot_longer()` from the `tidyr` package helps us do  this conversion. \nIf you do not remember all the arguments that go into `pivot_longer()` you can always call the `help` page by typing `?pivot_longer` in the console.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_long <- catch_clean %>% \n    #pivot longer all columns except Region and Year\n    pivot_longer(\n        cols = -c(Region, Year),\n        names_to = \"species\",\n        values_to = \"catch\"\n    )\n\nhead(catch_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  Region  Year species catch\n  <chr>  <dbl> <chr>   <dbl>\n1 SSE     1886 Chinook     0\n2 SSE     1886 Sockeye     5\n3 SSE     1886 Coho        0\n4 SSE     1886 Pink        0\n5 SSE     1886 Chum        0\n6 SSE     1887 Chinook     0\n```\n\n\n:::\n:::\n\n\n\n\nThe syntax we used above for `pivot_longer()` might be a bit confusing so let's walk though it.\n\n- The first argument to `pivot_longer` is the columns over which we are pivoting. You can select these by listing either the names of the columns you do want to pivot, or in this case, the names of the columns you are not pivoting over. \n\n- The `names_to` argument: this is the name of the column that you are creating from the column **names** of the columns you are pivoting over. \n\n- The `values_to` argument: the name of the column that you are creating from the **values** in the columns you are pivoting over.\n\nThe opposite of `pivot_longer()` is the `pivot_wider()` function. It works in a similar declarative fashion:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_wide <- catch_long %>%\n    pivot_wider(names_from = species,\n                values_from = catch)\n\nhead(catch_wide)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  <chr>  <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 SSE     1886       0       5     0     0     0\n2 SSE     1887       0     155     0     0     0\n3 SSE     1888       0     224    16     0     0\n4 SSE     1889       0     182    11    92     0\n5 SSE     1890       0     251    42     0     0\n6 SSE     1891       0     274    24     0     0\n```\n\n\n:::\n:::\n\n\n\n\nSame than we did above we can pull up the documentation of the function to remind ourselves what goes in which argument. Type `?pivot_wider` in the console.\n\n## Renaming columns with `rename()`\n\nIf you scan through the data, you may notice the values in the `catch` column are very small (these are supposed to be annual catches). \nIf we look at [the metadata](https://knb.ecoinformatics.org/#view/df35b.304.2) we can see that the `catch` column is in thousands of fish, so let's convert it before moving on.\n\nLet's first rename the `catch` column to be called `catch_thousands`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_long <- catch_long %>%\n    rename(catch_thousands = catch)\n\nhead(catch_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  Region  Year species catch_thousands\n  <chr>  <dbl> <chr>             <dbl>\n1 SSE     1886 Chinook               0\n2 SSE     1886 Sockeye               5\n3 SSE     1886 Coho                  0\n4 SSE     1886 Pink                  0\n5 SSE     1886 Chum                  0\n6 SSE     1887 Chinook               0\n```\n\n\n:::\n:::\n\n\n\n\n::: callout-important\n\n## `names()` versus `rename()`\n\nMany people use the base R function `names()` to rename columns, often in combination with column indexing that relies on columns being in a particular order. Column indexing is often also used to select columns instead of the `select()` function from `dplyr`. \nAlthough these methods work just fine, they do have one major drawback: in most implementations they rely on you knowing exactly the column order your data is in.\n\n**To illustrate why your knowledge of column order isn't reliable enough for these operations, considering the following scenario:**\n\nYour colleague emails you letting you know that she has an updated version of the conductivity-temperature-depth data from this year's research cruise, and sends it along. Excited, you re-run your scripts that use this data for your phytoplankton research. You run the script and suddenly all of your numbers seem off. You spend hours trying to figure out what is going on.\n\nUnbeknownst to you, your colleagues bought a new sensor this year that measures dissolved oxygen. Because of the new variables in the data set, the column order is different. Your script which previously renamed the fourth column, `SAL_PSU` to `salinity` now renames the fourth column, `O2_MGpL` to `salinity`. No wonder your results looked so weird, good thing you caught it!\n\nIf you had written your code so that it doesn't rely on column order, but instead renames columns using the `rename()` function, the code would have run just fine (assuming the name of the original salinity column didn't change, in which case the code would have thrown an error in an obvious way). \nThis is an example of a *defensive coding strategy*, where you try to anticipate issues before they arise, and write your code in such a way as to keep the issues from happening.\n\n::: \n\n\n\n## Adding columns using `mutate()`\n\nNow let's use `mutate()` again to create a new column called `catch` with units of fish (instead of thousands of fish).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_long <- catch_long %>%\n    mutate(catch = catch_thousands * 1000)\n\nhead(catch_long)\n```\n:::\n\n\n\n\nLet's remove the `catch_thousands` column for now since we don't need it. Note that here we have added to the expression we wrote above by adding another function call (mutate) to our expression. This takes advantage of the pipe operator by grouping together a similar set of statements, which all aim to clean up the `catch_clean` data frame.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncatch_long <- catch_long %>%\n    mutate(catch = catch_thousands * 1000) %>%\n    select(-catch_thousands)\n\nhead(catch_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  Region  Year species catch\n  <chr>  <dbl> <chr>   <dbl>\n1 SSE     1886 Chinook     0\n2 SSE     1886 Sockeye  5000\n3 SSE     1886 Coho        0\n4 SSE     1886 Pink        0\n5 SSE     1886 Chum        0\n6 SSE     1887 Chinook     0\n```\n\n\n:::\n:::\n\n\n\n\nWe're now ready to start analyzing the data.\n\n## Summary statistics using `group_by()` and `summarize()`\n\nSuppose we are now interested in getting the average catch per region. \nIn our initial data exploration we saw there are 18 regions, we can easily see their names again:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(catch_original$Region)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"SSE\" \"NSE\" \"YAK\" \"GSE\" \"BER\" \"COP\" \"PWS\" \"CKI\" \"BRB\" \"KSK\" \"YUK\" \"NRS\"\n[13] \"KTZ\" \"KOD\" \"CHG\" \"SOP\" \"ALU\" \"NOP\"\n```\n\n\n:::\n:::\n\n\n\n\nThink about how we would calculate the average catch per region \"by hand\". It would be something like this: \n\n0. We start with our table and notice there are multiple regions in the \"Regions\" column. \n\n\n1. We split our original table to group all observations from the same region together. \n\n\n2. We calculate the average catch for each of the groups we form. \n\n\n3. Then we combine the values for average catch per region into a single table. \n\n:::{.column-body-outset}\n![](images/r_tidyverse_clean_wrangle/regions-split-apply-combine.png){ fig-align=\"center\"}\n:::\n\nAnalyses like this conform to what is known as the **Split-Apply-Combine strategy**. This strategy follows the three steps we explained above:\n\n1. **Split**: Split the data into logical groups (e.g., region, species, etc.)\n2. **Apply**: Calculate some summary statistic on each group (e.g. mean catch *by* year, number of individuals *per* species)\n3. **Combine**: Combine the statistic calculated on each group back together into a single table\n\nThe `dplyr` library lets us easily employ the Split-Apply-Combine strategy by using the `group_by()` and `summarize()` functions:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_region <- catch_long %>%\n    group_by(Region) %>%\n    summarize(mean_catch = mean(catch))\n\nhead(mean_region)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  Region mean_catch\n  <chr>       <dbl>\n1 ALU        40384.\n2 BER        16373.\n3 BRB      2709796.\n4 CHG       315487.\n5 CKI       683571.\n6 COP       179223.\n```\n\n\n:::\n:::\n\n\n\n\nLet's see how the previous code implements the Split-Apply-Combine strategy:\n\n1. `group_by(Region)`: this is telling R to **split** the dataframe and create a group for each different value in the column `Region`. R just keeps track of the groups, it doesn't return separate dataframes per region. \n\n\n2. `mean(catch)`: here `mean` is the function we want to **apply** to the column `catch` in each group.\n\n\n3. `summarize(catch = mean(catch))` the function `summarize()` is used to **combine** the results of `mean(catch)` in each group into a single table. The argument `mean_catch = mean(catch)` indicates that the column having the results of `mean(catch)` will be named `mean_catch`. \n\nAnother common use of `group_by()` followed by `summarize()` is to count the number of rows in each group. We have to use a special function from `dplyr`, `n()`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_region <- catch_long %>%\n    group_by(Region) %>%\n    summarize(n = n())\n\nhead(n_region)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  Region     n\n  <chr>  <int>\n1 ALU      435\n2 BER      510\n3 BRB      570\n4 CHG      550\n5 CKI      525\n6 COP      470\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-caution icon=false}\n## Try using `count()`\n\nIf you are finding that you are reaching for this combination of `group_by()`, `summarize()` and `n()` a lot, there is a helpful `dplyr` function `count()` that accomplishes this in one function!\n:::\n\n::: {.callout-note icon=false}\n## Exercise\n\n- Find another grouping and statistic to calculate for each group.\n- Find out if you can group by multiple variables.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Answer\"}\n## for example:\ncatch_year_sp <- catch_long %>%\n    group_by(Year, species) %>%\n    summarize(total_year = sum(catch, na.rm = T))\n```\n:::\n\n\n\n:::\n\n\n## Filtering rows using `filter()`\n\nWe use the `filter()` function to filter our `data.frame` to rows matching some condition. It's similar to `subset()` from base R.\n\nLet's go back to our original `data.frame` and do some `filter()`ing:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsse_catch <- catch_long %>%\n    filter(Region == \"SSE\")\n\nhead(sse_catch)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  Region  Year species catch\n  <chr>  <dbl> <chr>   <dbl>\n1 SSE     1886 Chinook     0\n2 SSE     1886 Sockeye  5000\n3 SSE     1886 Coho        0\n4 SSE     1886 Pink        0\n5 SSE     1886 Chum        0\n6 SSE     1887 Chinook     0\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-note icon=false}\n## Exercise\n\n- Filter to just catches of over one million fish\n- Filter to just Chinook from the SSE region\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Answer\"}\n## Catches over a million fish\ncatch_million <- catch_long %>%\n    filter(catch > 1000000)\n\n## Chinook from SSE data\nchinook_see <- catch_long %>%\n    filter(Region == \"SSE\",\n           species == \"Chinook\")\n\n## OR\nchinook_see <- catch_long %>%\n    filter(Region == \"SSE\" & species == \"Chinook\")\n```\n:::\n\n\n\n:::\n\n\n## Sorting your data using `arrange()`\n\nThe `arrange()` function is used to sort the rows of a `data.frame`. Two common cases to use `arrange()` are:\n\n- To calculate a cumulative sum (with `cumsum()`) so row order matters\n- To display a table (like in an `.qmd` document) in sorted order\n\nLet's re-calculate mean catch by region, and then `arrange()` the output by mean catch:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_region <- catch_long %>%\n    group_by(Region) %>%\n    summarize(mean_catch = mean(catch)) %>%\n    arrange(mean_catch)\n\nhead(mean_region)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  Region mean_catch\n  <chr>       <dbl>\n1 BER        16373.\n2 KTZ        18836.\n3 ALU        40384.\n4 NRS        51503.\n5 KSK        67642.\n6 YUK        68646.\n```\n\n\n:::\n:::\n\n\n\n\n\nThe default sorting order of `arrange()` is to sort in ascending order. To reverse the sort order, wrap the column name inside the `desc()` function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_region <- catch_long %>%\n    group_by(Region) %>%\n    summarize(mean_catch = mean(catch)) %>%\n    arrange(desc(mean_catch))\n\nhead(mean_region)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  Region mean_catch\n  <chr>       <dbl>\n1 SSE      3184661.\n2 BRB      2709796.\n3 NSE      1825021.\n4 KOD      1528350 \n5 PWS      1419237.\n6 SOP      1110942.\n```\n\n\n:::\n:::\n\n\n\n\n## Splitting a column using `separate()` and `unite()`\n\nThe `separate()` function allow us to easily split a single column into numerous. Its complement, the `unite()` function, allows us to combine multiple columns into a single one.\n\nThis can come in really handy when we need to split a column into two pieces by a consistent separator (like a dash).\n\nLet's make a new `data.frame` with fake data to illustrate this. Here we have a set of site identification codes with information about the island where the site is (the first 3 letters) and a site number (the 3 numbers). If we want to group and summarize by island, we need a column with just the island information.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsites_df <- data.frame(site = c(\"HAW-101\",\n                                \"HAW-103\",\n                                \"OAH-320\",\n                                \"OAH-219\",\n                                \"MAU-039\"))\n\nsites_df %>%\n    separate(site, c(\"island\", \"site_number\"), \"-\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  island site_number\n1    HAW         101\n2    HAW         103\n3    OAH         320\n4    OAH         219\n5    MAU         039\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-note icon=false}\n## Exercise\n\nSplit the `city` column in the data frame `cities_df` into `city` and `state_code` columns\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## create `cities_df`\ncities_df <- data.frame(city = c(\"Juneau AK\",\n                                 \"Sitka AK\",\n                                 \"Anchorage AK\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Answer\"}\ncolnames(cities_df)\n\ncities_clean <- cities_df %>%\n    separate(city, c(\"city\", \"state_code\"), \" \")\n```\n:::\n\n\n\n:::\n\nThe `unite()` function does just the reverse of `separate()`. If we have a `data.frame` that contains columns for year, month, and day, we might want to unite these into a single date column.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndates_df <- data.frame(\n    year = c(\"1930\",\n             \"1930\",\n             \"1930\"),\n    month = c(\"12\",\n              \"12\",\n              \"12\"),\n    day = c(\"14\",\n            \"15\",\n            \"16\")\n)\n\ndates_df %>%\n    unite(date, year, month, day, sep = \"-\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        date\n1 1930-12-14\n2 1930-12-15\n3 1930-12-16\n```\n\n\n:::\n:::\n\n\n\n\n## Now, all together!\n\nWe just ran through the various things we can do with `dplyr` and `tidyr` but if you're wondering how this might look in a real analysis. Let's look at that now:\n\n\n\n\n::: {.cell catch='true'}\n\n```{.r .cell-code}\ncatch_original <- read_csv(\"https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1\")\n\nmean_region <- catch_original %>%\n  select(-All, -notesRegCode) %>% \n  mutate(Chinook = if_else(Chinook == \"I\", \"1\", Chinook)) %>% \n  mutate(Chinook = as.numeric(Chinook)) %>% \n  pivot_longer(-c(Region, Year), \n               names_to = \"species\", \n               values_to = \"catch\") %>%\n  mutate(catch = catch*1000) %>% \n  group_by(Region) %>% \n  summarize(mean_catch = mean(catch)) %>% \n  arrange(desc(mean_catch))\n\nhead(mean_region)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  Region mean_catch\n  <chr>       <dbl>\n1 SSE      3184661.\n2 BRB      2709796.\n3 NSE      1825021.\n4 KOD      1528350 \n5 PWS      1419237.\n6 SOP      1110942.\n```\n\n\n:::\n:::\n\n\n\n\n\nWe have completed our lesson on Cleaning and Wrangling data. Before we break, let's practice our Git workflow.\n\n::: {.callout-tip icon=false}\n## Steps\n\n1. Save the `.qmd` you have been working on for this lesson.\n2. Render the Quarto file. This is a way to test everything in your code is working.\n\n3. ```Stage (Add) > Commit > Pull > Push```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}