[
  {
    "objectID": "s03_r_programming_introduction.html",
    "href": "s03_r_programming_introduction.html",
    "title": "Working in R & RStudio",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nGet oriented with the RStudio interface\nRun code and basic arithmetic in the Console\nPractice writing code in an R Script\nBe introduced to built-in R functions\nUse the Help pages to look up function documentation\nFull Screen",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#welcome-to-r-programming",
    "href": "s03_r_programming_introduction.html#welcome-to-r-programming",
    "title": "Working in R & RStudio",
    "section": "1 Welcome to R Programming",
    "text": "1 Welcome to R Programming\n\n\n\nArtwork by Allison Horst\n\n\nThere is a vibrant community out there that is collectively developing increasingly easy to use and powerful open source programming tools. The changing landscape of programming is making learning how to code easier than it ever has been. Incorporating programming into analysis workflows not only makes science more efficient, but also more computationally reproducible. In this course, we will use the programming language R, and the accompanying integrated development environment (IDE) RStudio. R is a great language to learn for data-oriented programming because it is widely adopted, user-friendly, and (most importantly) open source!\nSo what is the difference between R and RStudio? Here is an analogy to start us off. If you were a chef, R is a knife. You have food to prepare, and the knife is one of the tools that you’ll use to accomplish your task.\nAnd if R were a knife, RStudio is the kitchen. RStudio provides a place to do your work! RStudio makes your life as a researcher easier by bringing together other tools you need to do your work efficiently - like a file browser, data viewer, help pages, terminal, community, support, the list goes on. So it’s not just the infrastructure (the user interface or IDE), although it is a great way to learn and interact with your variables, files, and interact directly with git. It’s also data science philosophy, R packages, community, and more. Although you can prepare food without a kitchen and we could learn R without RStudio, that’s not what we’re going to do. We are going to take advantage of the great RStudio support, and learn R and RStudio together.\nSomething else to start us off is to mention that you are learning a new language here. It’s an ongoing process, it takes time, you’ll make mistakes, it can be frustrating, but it will be overwhelmingly awesome in the long run. We all speak at least one language; it’s a similar process, really. And no matter how fluent you are, you’ll always be learning, you’ll be trying things in new contexts, learning words that mean the same as others, etc, just like everybody else. And just like any form of communication, there will be miscommunication that can be frustrating, but hands down we are all better off because of it.\nWhile language is a familiar concept, programming languages are in a different context from spoken languages and you will understand this context with time. For example: you have a concept that there is a first meal of the day, and there is a name for that: in English it’s “breakfast.” So if you’re learning Spanish, you could expect there is a word for this concept of a first meal. (And you’d be right: “desayuno”). We will get you to expect that programming languages also have words (called functions in R) for concepts as well. You’ll soon expect that there is a way to order values numerically. Or alphabetically. Or search for patterns in text. Or calculate the median. Or reorganize columns to rows. Or subset exactly what you want. We will get you to increase your expectations and learn to ask and find what you’re looking for.",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#rstudio-ide",
    "href": "s03_r_programming_introduction.html#rstudio-ide",
    "title": "Working in R & RStudio",
    "section": "2 RStudio IDE",
    "text": "2 RStudio IDE\nLet’s take a tour of the RStudio interface.\n\nNotice the default panes:\n\nConsole (entire left)\nEnvironment/History (tabbed in upper right)\nFiles/Plots/Packages/Help (tabbed in lower right)\n\n\n\n\n\n\n\nQuick Tip\n\n\n\nYou can change the default location of the panes, among many other things, see Customizing RStudio.",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#coding-in-the-console",
    "href": "s03_r_programming_introduction.html#coding-in-the-console",
    "title": "Working in R & RStudio",
    "section": "3 Coding in the Console",
    "text": "3 Coding in the Console\n\n\n\n\n\n\nBut first, an important first question: where are we?\n\n\n\nIf you’ve just opened RStudio for the first time, you’ll be in your Home directory. This is noted by the ~/ at the top of the console. You can see too that the Files pane in the lower right shows what is in the Home directory where you are. You can navigate around within that Files pane and explore, but note that you won’t change where you are: even as you click through you’ll still be Home: ~/.\n\n\n\n\n\n\n\nWe can run code in a couple of places in RStudio, including the Console, let’s start there.\nAt it’s most basic, we can use R as a calculator, let’s try a couple of examples in the console.\n\n# run in the console\n# really basic examples\n3*4\n3+4\n3-4\n3/4\n\nWhile there are many cases where it makes sense to type code directly in to the the console, it is not a great place to write most of your code since you can’t save what you ran. A better way is to create an R Script, and write your code there. Then when you run your code from the script, you can save it when you are done. We’re going to continue writing code in the Console for now, but we’ll code in an R Script later in this lesson\n\n\n\n\n\n\nQuick Tip\n\n\n\nWhen you’re in the console you’ll see a greater than sign (&gt;) at the start of a line. This is called the “prompt” and when we see it, it means R is ready to accept commands. If you see a plus sign (+) in the Console, it means R is waiting on additional information before running. You can always press escape (esc) to return to the prompt. Try practicing this by running 3* (or any incomplete expression) in the console.\n\n\n\n3.1 Objects in R\nLet’s say the value of 12 that we got from running 3*4 is a really important value we need to keep. To keep information in R, we need to create an object. The way information is stored in R is through objects.\nWe can assign a value of a mathematical operation (and more!) to an object in R using the assignment operator, &lt;- (greater than sign and minus sign). All objects in R are created using the assignment operator, following this form: object_name &lt;- value.\n\n\n\n\n\n\nExercise 1\n\n\n\n\n\n\nCreate an object!\nAssign 3*4 to an object called important_value and then inspect the object you just created.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n# think of this code as someone saying \"important_value gets 12\".\nimportant_value &lt;- 3*4\n\nNotice how after creating the object, R doesn’t print anything. However, we know our code worked because we see the object, and the value we wanted to store is now visible in our Global Environment. We can force R to print the value of the object by calling the object name (aka typing it out) or by using parentheses.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuick Tip\n\n\n\nWhen you begin typing an object name RStudio will automatically show suggested completions for you that you can select by hitting tab, then press return.\n\n\n\n# printing the object by calling the object name\nimportant_value\n\n[1] 12\n\n# printing the object by wrapping the assignment syntax in parentheses\n(important_value &lt;- 3*4)\n\n[1] 12\n\n\n\n\n\n\n\n\nQuick Tip\n\n\n\nWhen you’re in the Console use the up and down arrow keys to call your command history, with the most recent commands being shown first.\n\n\n\n\n3.2 Naming Conventions\nBefore we run more calculations, let’s talk about naming objects. For the object, important_value we used an underscore to separate the object name. This naming convention is called snake case. There are other naming conventions including, but not limited to:\n\nwe_used_snake_case\nsomeUseCamelCase\nSomeUseUpperCamelCaseAlsoCalledPascalCase\n\nChoosing a naming convention is a personal preference, but once you choose one - be consistent! A consistent naming convention will increase the readability of your code for others and your future self.\n\n\n\n\n\n\nQuick Tip\n\n\n\nObject names cannot start with a digit and cannot contain certain characters such as a comma or a space.",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#running-code-in-an-r-script",
    "href": "s03_r_programming_introduction.html#running-code-in-an-r-script",
    "title": "Working in R & RStudio",
    "section": "4 Running code in an R Script",
    "text": "4 Running code in an R Script\nSo far we’ve been running code in the Console, let’s try running code in an R Script. An R Script is a simple text file. RStudio uses an R Script by copying R commands from text in the file and pastes them into the Console as if you were manually entering commands yourself.\n\n\n\n\n\n\nCreating an R Script\n\n\n\n\nFrom the “File” menu, select “New File”\nClick “R Script” from the list of options\n\nRStudio should open your R Script automatically after creating it. Notice a new pane appears above the Console. This is called the Source pane and is where we write and edit R code and documents. This pane is only present if there are files open in the editor.\n\nSave the R Script in your script folder, name the file intro-to-programming.R\n\n\n\n\n4.1 How to run code in an R Script\nRunning code in an R Script is different than running code in the Console (aka you can’t just press return / enter). To interpret and run the code you’ve written, R needs you to send the code from the script (or editor) to the Console. Some common ways to run code in an R Script include:\n\nPlace your cursor on the line of code you want to run and use the shortcut command + return or click the Run button in the top right of the Source pane.\nHighlight the code you want to run, then use the shortcut command + return or click the Run button.\n\n\n\n4.2 R calculations with objects\nSo we know that objects are how R stores information, and we know we create objects using the assignment operator &lt;-. Let’s build upon that and learn how to use an object in calculations.\nImagine we have the weight of a dog in kilograms. Create the object weight_kg and assign it a value of 25.\n\n# weight of a dog in kilograms\nweight_kg &lt;- 25\n\nNow that R has weight_kg saved in the Global Environment, we can run calculations with it.\n\n\n\n\n\n\nExercise 2\n\n\n\n\n\n\nUsing weight_kg run a simple calculation\nLet’s convert the weight into pounds. Weight in pounds is 2.2 times the weight in kg.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n# converting weight from kilograms to pounds\n2.2 * weight_kg\n\n[1] 55\n\n\n\n\n\n\n\n\n\n\nYou can also store more than one value in a single object. Storing a series of weights in a single object is a convenient way to perform the same operation on multiple values at the same time. One way to create such an object is with the function c(), which stands for combine or concatenate.\nFirst let’s create a vector of weights in kilograms using c() (we’ll talk more about vectors in the next section, Data structures in R).\n\n# create a vector of weights in kilograms\nweight_kg &lt;- c(25, 33, 12)\n# call the object to inspect\nweight_kg\n\n[1] 25 33 12\n\n\nNow convert the vector weight_kg to pounds.\n\n# covert `weight_kg` to pounds \nweight_kg * 2.2\n\n[1] 55.0 72.6 26.4\n\n\nWouldn’t it be helpful if we could save these new weight values we just converted? This might be important information we may need for a future calculation. How would you save these new weights in pounds?\n\n# create a new object \nweight_lb &lt;- weight_kg * 2.2\n# call `weight_lb` to check if the information you expect is there\nweight_lb\n\n[1] 55.0 72.6 26.4\n\n\n\n\n\n\n\n\nQuick Tip\n\n\n\nYou will make many objects and the assignment operator &lt;- can be tedious to type over and over. Instead, use RStudio’s keyboard shortcut: option + - (the minus sign).\nNotice that RStudio automatically surrounds &lt;- with spaces, which demonstrates a useful code formatting practice. Code is miserable to read on a good day. Give your eyes a break and use spaces.\nRStudio offers many handy keyboard shortcuts. Also, option+Shift+K brings up a keyboard shortcut reference card.\nFor more RStudio tips, check out Master of Environmental Data Science (MEDS) workshop: IDE Tips & Tricks.",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#data-types-class-in-r",
    "href": "s03_r_programming_introduction.html#data-types-class-in-r",
    "title": "Working in R & RStudio",
    "section": "5 Data types (class) in R",
    "text": "5 Data types (class) in R\n\nCommon data types in R\n\n\n\n\n\n\nData Type\nDefinition\n\n\n\n\nboolean (also called logical)\nData take on the value of either TRUE, FALSE, or NA. NA is used to represent missing values.\n\n\ncharacter\nData are string values. You can think of character strings as something like a word (or multiple words). A special type of character string is a factor, which is a string but with additional attributes (like levels or an order).\n\n\ninteger\nData are whole numbers (those numbers without a decimal point). To explicitly create an integer data type, use the suffix L (e.g. 2L).\n\n\nnumeric (also called double)\nData are numbers that contain a decimal.\n\n\n\n\nLess common data types (we won’t be going into these data types this course)\n\n\n\n\n\n\nData Type\nDefinition\n\n\n\n\ncomplex\nData are complex numbers with real and imaginary parts.\n\n\nraw\nData are raw bytes.\n\n\n\nWe’ve been using primarily integer or numeric data types so far. Let’s create an object that has a string value or a character data type.\n\nscience_rocks &lt;- \"yes it does!\"\n\n“yes it does!” is a string, and R knows it’s a word and not a number because it has quotes \" \". You can work with strings in your data in R easily thanks to the stringr and tidytext packages.\nThis lead us to an important concept in programming: As we now know, there are different “classes” or types of objects in R. The operations you can do with an object will depend on what type of object it is because each object has their own specialized format, designed for a specific purpose. This makes sense! Just like you wouldn’t do certain things with your car (like use it to eat soup), you won’t do certain operations with character objects (strings).\nAlso, everything in R is an object. An object is a variable, function, data structure, or method that you have written to your environment.\nTry running the following line in your script:\n\n\"Hello world!\" * 3\n\nWhat happened? What do you see in the Console? Why?\n\n\n\n\n\n\nQuick Tip\n\n\n\nYou can see what data type or class an object is using the class() function, or you can use a logical test such as: is.numeric(), is.character(), is.logical(), and so on.\n\nclass(science_rocks) # returns character\nis.numeric(science_rocks) # returns FALSE\nis.character(science_rocks) # returns TRUE",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#data_structures",
    "href": "s03_r_programming_introduction.html#data_structures",
    "title": "Working in R & RStudio",
    "section": "6 Data structures in R",
    "text": "6 Data structures in R\nOkay, now let’s talk about vectors.\nA vector is the most common and most basic data structure in R. Vectors can be thought of as a way R stores a collection of values or elements. Think back to our weight_lb vector. That was a vector of three elements each with a data type or class of numeric.\nWhat we’re describing is a specific type of vector called atomic vectors. To put it simply, atomic vectors only contain elements of the same data type. Atomic vectors are very common.\nVectors are foundational for other data structures in R, including data frames, and while we won’t go into detail about other data structures there are great resources online that do. We recommend the chapter Vectors from the online book Advanced R by Hadley Wickham.\n\n# atomic vector examples #\n# character vector\nchr_vector &lt;- c(\"hello\", \"good bye\", \"see you later\")\n# numeric vector\nnumeric_vector &lt;- c(5, 1.3, 10)\n# logical vector\nboolean_vector &lt;- c(TRUE, FALSE, TRUE)",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#r-functions",
    "href": "s03_r_programming_introduction.html#r-functions",
    "title": "Working in R & RStudio",
    "section": "7 R Functions",
    "text": "7 R Functions\nSo far we’ve learned some of the basic syntax and concepts of R programming, and how to navigate RStudio, but we haven’t done any complicated or interesting programming processes yet. This is where functions come in!\nA function is a way to group a set of commands together to undertake a task in a reusable way. When a function is executed, it produces a return value. We often say that we are “calling” a function when it is executed. Functions can be user defined and saved to an object using the assignment operator, so you can write whatever functions you need, but R also has a mind-blowing collection of built-in functions ready to use. To start, we will be using some built in R functions.\nAll functions are called using the same syntax: function name with parentheses around what the function needs in order to do what it was built to do. These “needs” are pieces of information called arguments, and are required to return an expected value.\n\n\n\n\n\n\nSyntax of a function will look something like:\n\n\n\nresult_value &lt;- function_name(argument1 = value1, argument2 = value2, ...)\n\n\nBefore we use a function, let’s talk about Help pages.",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#getting-help-using-help-pages",
    "href": "s03_r_programming_introduction.html#getting-help-using-help-pages",
    "title": "Working in R & RStudio",
    "section": "8 Getting help using help pages",
    "text": "8 Getting help using help pages\nWhat if you know the name of the function that you want to use, but don’t know exactly how to use it? Thankfully RStudio provides an easy way to access the help documentation for functions.\nThe next function we’re about to use is the mean() function.\nTo access the help page for mean(), enter the following into your console:\n\n?mean\n\nThe Help pane will show up in the lower right hand corner of your RStudio.\nThe Help page is broken down into sections:\n\nDescription: An extended description of what the function does.\nUsage: The arguments of the function(s) and their default values.\nArguments: An explanation of the data each argument is expecting.\nDetails: Any important details to be aware of.\nValue: The data the function returns.\nSee Also: Any related functions you might find useful.\nExamples: Some examples for how to use the function.\n\nAnd there’s also help for when you only sort of remember the function name: double-question mark:\n\n??install \n\n\n\n\n\n\n\nNot all functions have (or require) arguments\n\n\n\nCheck out the documentation or Help page for date().\n\n?date()",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#examples-using-built-in-r-functions-mean-and-read.csv",
    "href": "s03_r_programming_introduction.html#examples-using-built-in-r-functions-mean-and-read.csv",
    "title": "Working in R & RStudio",
    "section": "9 Examples using built-in R functions mean() and read.csv()",
    "text": "9 Examples using built-in R functions mean() and read.csv()\n\n9.1 Use the mean() function to run a more complex calculation\nLet’s override our weight object with some new values, and this time we’ll assign it three dog weights in pounds:\n\nweight_lb &lt;- c(55, 25, 12)\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\n\n\nUse the mean() function to calculate the mean weight.\nFrom the its Help page, we learned this function will take the mean of a set of numbers. Very convenient!\nWe also learned that mean() only has one argument we need to supply a value to (x). The rest of the arguments have default values.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nmean(x = weight_lb)\n\n[1] 30.66667\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\n\n\n\nSave the mean to an object called mean_weight_lb\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nWhat operator do we use to save values to an object?\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n# saving the mean using the assignment operator `&lt;-`\nmean_weight_lb &lt;- mean(x = weight_lb)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 5\n\n\n\n\n\n\nUpdate weight_lb\nLet’s say each of the dogs gained 5 pounds and we need to update our vector, so let’s change our object’s value by assigning it new values.\n\nweight_lb &lt;- c(60, 30, 17)\n\nCall mean_weight_lb in the console or take a look at your Global Environment. Is that the value you expected? Why or why not?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nPerhaps you expected mean_weight_lb to change when you changed weight_lb? It did not! This demonstrates an important R programming concept: Assigning a value to one object does not change the values of other objects in R.\n\n\n\n\n\n\n\n\nNow that we understand why the object’s value hasn’t changed - how do we update the value of mean_weight_lb? How is an R Script useful for this?\nThis lead us to another important programming concept, specifically for R Scripts: An R Script runs top to bottom.\nThis order of operations is important because if you are running code line by line, the values in object may be unexpected. When you are done writing your code in an R Script, it’s good practice to clear your Global Environment and use the Run button and select “Run all” to test that your R Script successfully runs top to bottom.\n\n\n9.2 Use the read.csv() function to read a file into R\nSo far we have learned how to assign values to objects in R, and what a function is, but we haven’t quite put it all together yet with real data yet. To do this, we will introduce the function read.csv(), which will be in the first lines of many of your future scripts. It does exactly what it says, it reads in a csv file to R.\nSince this is our first time using this function, first access the help page for read.csv(). This has a lot of information in it, as this function has a lot of arguments, and the first one is especially important - we have to tell it what file to look for. Let’s get a file!\n\n\n\n\n\n\nDownload a file from the Arctic Data Center\n\n\n\n\nNavigate to this dataset by Craig Tweedie that is published on the Arctic Data Center. Craig Tweedie. 2009. North Pole Environmental Observatory Bottle Chemistry. Arctic Data Center. doi:10.18739/A25T3FZ8X.\nDownload the first csv file called BGchem2008data.csv by clicking the “download” button next to the file.\nClick the “Upload” button in your RStudio server file browser.\nIn the dialog box, make sure the destination directory is the data directory in your R project, click “Choose File,” and locate the BGchem2008data.csv file. Press “OK” to upload the file.\nCheck your file was successfully uploaded by navigating into your data folder in the Files pane.\n\n\n\nNow we have to tell read.csv() how to find the file. We do this using the file argument which you can see in the usage section in the help page. In R, you can either use absolute paths (which will start with your home directory ~/) or paths relative to your current working directory. RStudio has some great auto-complete capabilities when using relative paths, so we will go that route.\nAssuming you have moved your file to a folder within training_{USERNAME} called data, and your working directory is your project directory (training_{USERNAME}) your read.csv() call will look like this:\n\n# reading in data using relative paths\nbg_chem_dat &lt;- read.csv(file = \"data/BGchem2008data.csv\")\n\nYou should now have an object of the class data.frame in your environment called bg_chem_dat. Check your environment pane to ensure this is true. Or you can check the class using the function class() in the console.\n\n\n\n\n\n\nOptional Arguments\n\n\n\nNotice that in the Help page there are many arguments that we didn’t use in the call above. Some of the arguments in function calls are optional, and some are required.\nOptional arguments will be shown in the usage section with a name = value pair, with the default value shown. If you do not specify a name = value pair for that argument in your function call, the function will assume the default value (example: header = TRUE for read.csv()).\nRequired arguments will only show the name of the argument, without a value. Note that the only required argument for read.csv() is file.\n\n\nYou can always specify arguments in name = value form. But if you do not, R attempts to resolve by position. So above, it is assumed that we want file = \"data/BGchem2008data.csv\", since file is the first argument.\nIf we explicitly called the file argument our code would like this:\n\nbg_chem_dat &lt;- read.csv(file = \"data/BGchem2008data.csv\")\n\nIf we wanted to add another argument, say stringsAsFactors, we need to specify it explicitly using the name = value pair, since the second argument is header.\nMany R users (including myself) will set the stringsAsFactors argument using the following call:\n\n# relative file path\nbg_chem_dat &lt;- read.csv(\"data/BGchem2008data.csv\", stringsAsFactors = FALSE)\n\n\n\n\n\n\n\nQuick Tip\n\n\n\nFor functions that are used often, you’ll see many programmers will write code that does not explicitly call the first or second argument of a function.",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#working-with-data-frames-in-r-using-the-subset-operator",
    "href": "s03_r_programming_introduction.html#working-with-data-frames-in-r-using-the-subset-operator",
    "title": "Working in R & RStudio",
    "section": "10 Working with data frames in R using the Subset Operator $",
    "text": "10 Working with data frames in R using the Subset Operator $\nA data.frame is a list data structure in R that can represent tables and spreadsheets – we can think of it as a table. It is a collection of rows and columns of data, where each column has a name and represents a variable, and each row represents an observation containing a measurement of that variable. When we ran read.csv(), the object bg_chem_dat that we created was a data.frame. The columns in a data.frame might represent measured numeric response values (e.g., weight_kg), classifier variables (e.g., site_name), or categorical response variables (e.g., course_satisfaction). There are many ways R and RStudio help you explore data frames. Here are a few, give them each a try:\n\nClick on the word bg_chem_dat in the environment pane\nClick on the arrow next to bg_chem_dat in the environment pane\nExecute head(bg_chem_dat) in the Console\nExecute View(bg_chem_dat) in the Console\n\nUsually we will want to run functions on individual columns in a data.frame. To call a specific column, we use the list subset operator $.\nSay you want to look at the first few rows of the Date column only:\n\nhead(bg_chem_dat$Date)\n\nYou can also use the subset operator $ calculations. For example, let’s calculated the mean temperature of all the CTD samples.\n\nmean(bg_chem_dat$CTD_Temperature)\n\nYou can also save this calculation to an object that was created using the subset operator $.\n\nmean_temp &lt;- mean(bg_chem_dat$CTD_Temperature)\n\n\n\n\n\n\n\nOther ways to load tablular data\n\n\n\nWhile the base R package provides read.csv as a common way to load tabular data from text files, there are many other ways that can be convenient and will also produce a data.frame as output. Here are a few:\n\nUse the readr::read_csv() function from the Tidyverse to load the data file. The readr package has a bunch of convenient helpers and handles CSV files in typically expected ways, like properly typing dates and time columns. bg_chem_dat &lt;- readr::read_csv(\"data/BGchem2008data.csv\")\nLoad tabular data from Excel spreadsheets using the readxl::read_excel() function.\nLoad tabular data from Google Sheets using the googlesheets4::read_sheet() function.",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#error-messages-are-your-friends",
    "href": "s03_r_programming_introduction.html#error-messages-are-your-friends",
    "title": "Working in R & RStudio",
    "section": "11 Error messages are your friends",
    "text": "11 Error messages are your friends\nThere is an implicit contract with the computer/scripting language: Computer will do tedious computation for you. In return, you will be completely precise in your instructions. Typos matter. Case matters. Pay attention to how you type.\nRemember that this is a language, not dissimilar to English! There are times you aren’t understood – it’s going to happen. There are different ways this can happen. Sometimes you’ll get an error. This is like someone saying ‘What?’ or ‘Pardon’? Error messages can also be more useful, like when they say ‘I didn’t understand this specific part of what you said, I was expecting something else’. That is a great type of error message. Error messages are your friend. Google them (copy-and-paste!) to figure out what they mean. Note that knowing how to Google is a skill and takes practice - use our Masters of Environmental Data Science (MEDS) program workshop Teach Me How to Google as a guide.\n\n\n\n\n\n\n\n\n\n\nAnd also know that there are errors that can creep in more subtly, without an error message right away, when you are giving information that is understood, but not in the way you meant. Like if I’m telling a story about tables and you’re picturing where you eat breakfast and I’m talking about data. This can leave me thinking I’ve gotten something across that the listener (or R) interpreted very differently. And as I continue telling my story you get more and more confused… So write clean code and check your work as you go to minimize these circumstances!",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#r-packages",
    "href": "s03_r_programming_introduction.html#r-packages",
    "title": "Working in R & RStudio",
    "section": "12 R Packages",
    "text": "12 R Packages\n\n\n\nArtwork by Allison Horst\n\n\nR packages are the building blocks of computational reproducibility in R. Each package contains a set of related functions that enable you to more easily do a task or set of tasks in R. There are thousands of community-maintained packages out there for just about every imaginable use of R - including many that you have probably never thought of!\nTo install a package, we use the syntax install.packages(\"packge_name\"). A package only needs to be installed once, so this code can be run directly in the console if needed. Generally, you don’t want to save your install package calls in a script, because when you run the script it will re-install the package, which you only need to do once, or if you need to update the package.",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#r-resources",
    "href": "s03_r_programming_introduction.html#r-resources",
    "title": "Working in R & RStudio",
    "section": "13 R Resources",
    "text": "13 R Resources\n\nAwesome R Resources to Check out\n\n\n\n\n\n\nLearning R Resources\n\nIntroduction to R lesson in Data Carpentry’s R for data analysis course\nJenny Bryan’s Stat 545 course materials\nJulie Lowndes’ Data Science Training for the Ocean Health Index\nLearn R in the console with swirl\nProgramming in R\nR, RStudio, RMarkdown\n\n\n\nCommunity Resources\n\nNCEAS’ EcoDataScience\nR-Ladies\nrOpenSci\nMinorities in R (MiR)\nTwitter - there is a lot here but some hashtags to start with are:\n\n#rstats\n#TidyTuesday\n#dataviz\n\n\n\n\nCheatsheets\n\nBase R Cheatsheet\nLaTeX Equation Formatting\nMATLAB/R Translation Cheatsheet",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#clearing-the-environment",
    "href": "s03_r_programming_introduction.html#clearing-the-environment",
    "title": "Working in R & RStudio",
    "section": "14 Clearing the environment",
    "text": "14 Clearing the environment\nTake a look at the objects in your Environment (Workspace) in the upper right pane. The Workspace is where user-defined objects accumulate. There are a few useful commands for getting information about your Environment, which make it easier for you to reference your objects when your Environment gets filled with many, many objects.\n\nYou can get a listing of these objects with a couple of different R functions:\n\nobjects()\n\n[1] \"boolean_vector\"  \"chr_vector\"      \"important_value\" \"mean_weight_lb\" \n[5] \"numeric_vector\"  \"science_rocks\"   \"weight_kg\"       \"weight_lb\"      \n\nls()\n\n[1] \"boolean_vector\"  \"chr_vector\"      \"important_value\" \"mean_weight_lb\" \n[5] \"numeric_vector\"  \"science_rocks\"   \"weight_kg\"       \"weight_lb\"      \n\n\nIf you want to remove the object named weight_kg, you can do this:\n\nrm(weight_kg)\n\nTo remove everything (or click the Broom icon in the Environment pane):\n\nrm(list = ls())\n\n\n\n\n\n\n\nQuick Tip\n\n\n\nIt’s good practice to clear your environment. Over time your Global Environmental will fill up with many objects, and this can result in unexpected errors or objects being overridden with unexpected values. Also it’s difficult to read / reference your environment when it’s cluttered!",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#save-workspace-image-to-.rdata",
    "href": "s03_r_programming_introduction.html#save-workspace-image-to-.rdata",
    "title": "Working in R & RStudio",
    "section": "15 Save Workspace Image to .RData?",
    "text": "15 Save Workspace Image to .RData?\n\nDON’T SAVE\nWhen ever you close or switch projects you will be promped with the question: Do you want to save your workspace image to /“currente-project”/ .RData?\nRStudio by default wants to save the state of your environment (the objects you have in your environment pane) into the RData file so that when you open the project again you have the same environment. However, as we discussed above, it is good practice to constantly clear and clean your environment. It is generally NOT a good practice to rely on the state of your environment for your script to run and work. If you are coding reproducibly, your code should be able to reproduce the state of your environment (all the necessary objects) every time you run it. It is much better to rely on your code recreating the environment than the saving the workspace status.\nYou can change the Global Options configuration for the default to be NEVER SAVE MY WORKSPACE. Go to Tools &gt; Global Options. Under the General menu, select Never next to “Save workspace to .RData on exit”. This way you won’t get asked every time you close a project, instead RStudio knows not to save.",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s03_r_programming_introduction.html#logical-operators-and-expressions",
    "href": "s03_r_programming_introduction.html#logical-operators-and-expressions",
    "title": "Working in R & RStudio",
    "section": "16 Logical operators and expressions",
    "text": "16 Logical operators and expressions\nWe can ask questions about an object using logical operators and expressions. Let’s ask some “questions” about the weight_lb object we made.\n\n== means ‘is equal to’\n!= means ‘is not equal to’\n&lt; means ‘is less than’\n&gt; means ‘is greater than’\n&lt;= means ‘is less than or equal to’\n&gt;= means ‘is greater than or equal to’\n\n\n# examples using logical operators and expressions\nweight_lb == 2\nweight_lb &gt;= 30\nweight_lb != 5",
    "crumbs": [
      "Working in R & RStudio"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html",
    "href": "s04_r_tidyverse_clean_wrangle.html",
    "title": "Cleaning and Wrangling Data",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nIntroduce dplyr and tidyr functions to clean and wrangle data for analysis\nLearn about the Split-Apply-Combine strategy and how it applies to data wrangling\nDescribe the difference between wide vs. long table formats and how to convert between them",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#introduction",
    "href": "s04_r_tidyverse_clean_wrangle.html#introduction",
    "title": "Cleaning and Wrangling Data",
    "section": "1 Introduction",
    "text": "1 Introduction\nThe data we get to work with are rarely, if ever, in the format we need to do our analyses. It’s often the case that one package requires data in one format, while another package requires the data to be in another format. To be efficient analysts, we should have good tools for reformatting data for our needs so we can do further work like making plots and fitting models. The dplyr and tidyr R packages provide a fairly complete and extremely powerful set of functions for us to do this reformatting quickly. Learning these tools well will greatly increase your efficiency as an analyst.\nLet’s look at two motivating examples.\n\n\n\n\n\n\nExample 1\n\n\n\nSuppose you have the following data.frame called length_data with data about salmon length and want to calculate the average length per year.\n\n\n\nyear\nlength_cm\n\n\n\n\n1990\n5.673318\n\n\n1991\n3.081224\n\n\n1991\n4.592696\n\n\n1992\n4.381523\n\n\n1992\n5.597777\n\n\n1992\n4.900052\n\n\n\nBefore thinking about the code, let’s think about the steps we need to take to get to the answer (aka pseudocode).\nNow, how would we code this? The dplyr R library provides a fast and powerful way to do this calculation in a few lines of code:\n\n\nAnswer\nlength_data %&gt;% \n  group_by(year) %&gt;% \n  summarize(mean_length_cm = mean(length_cm))\n\n\n\n\n\n\n\n\n\n\nExample 2\n\n\n\nAnother process we often need to do is to “reshape” our data. Consider the following table that is in what we call “wide” format:\n\n\n\nsite\n1990\n1991\n…\n1993\n\n\n\n\ngold\n100\n118\n…\n112\n\n\nlake\n100\n118\n…\n112\n\n\n…\n…\n…\n…\n…\n\n\ndredge\n100\n118\n…\n112\n\n\n\nYou are probably familiar with data in the above format, where values of the variable being observed are spread out across columns. In this example we have a different column per year. This wide format works well for data entry and sometimes works well for analysis but we quickly outgrow it when using R (and know it is not tidy data!). For example, how would you fit a model with year as a predictor variable? In an ideal world, we’d be able to just run lm(length ~ year). But this won’t work on our wide data because lm() needs length and year to be columns in our table.\nWhat steps would you take to get this data frame in a long format?\nThe tidyr package allows us to quickly switch between wide format and long format using the pivot_longer() function:\n\n\nAnswer\nsite_data %&gt;% \n  pivot_longer(-site, \n               names_to = \"year\", \n               values_to = \"length\")\n\n\n\n\n\nsite\nyear\nlength\n\n\n\n\ngold\n1990\n101\n\n\nlake\n1990\n104\n\n\ndredge\n1990\n144\n\n\n…\n…\n…\n\n\ndredge\n1993\n145\n\n\n\n\n\nThis lesson will cover examples to learn about the functions you’ll most commonly use from the dplyr and tidyr packages:\n\nCommon dplyr functions\n\n\n\n\n\n\nFunction name\nDescription\n\n\n\n\nmutate()\nCreates modify and deletes columns\n\n\ngroup_by()\nGroups data by one or more variables\n\n\nsummarise()\nSummaries each group down to one row\n\n\nselect()\nKeep or drop columns using their names\n\n\nfilter()\nKeeps rows that matches conditions\n\n\narrange()\norder rows using columns variable\n\n\nrename()\nRename a column\n\n\n\n\nCommon tidyr functions\n\n\n\n\n\n\nFunction name\nDescription\n\n\n\n\npivot_longer()\ntransforms data from a wide to a long format\n\n\npivot_wider()\ntransforms data from a long to a wide format\n\n\nunite()\nUnite multiple columns into one by pasting strings together\n\n\nseparate()\nSeparate a character column into multiple columns with a regular expression or numeric locations",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#data-cleaning-basics",
    "href": "s04_r_tidyverse_clean_wrangle.html#data-cleaning-basics",
    "title": "Cleaning and Wrangling Data",
    "section": "2 Data cleaning basics",
    "text": "2 Data cleaning basics\nTo demonstrate, we’ll be working with a tidied up version of a data set from Alaska Department of Fish & Game containing commercial catch data from 1878-1997. The data set and reference to the original source can be found at its public archive.\n\n\n\n\n\n\nSetup\n\n\n\nFirst, open a new Quarto document. Delete everything below the setup chunk, and add a library chunk that calls dplyr, tidyr, and readr\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\n\n\n\n\n\n\n\n\n\nA note on loading packages\n\n\n\nYou may have noticed the following messages pop up when you ran your library chunk.\nAttaching package: ‘dplyr’\n\nThe following objects are masked from ‘package:stats’:\n\n    filter, lag\n\nThe following objects are masked from ‘package:base’:\n\n    intersect, setdiff, setequal, union\nThese are important messages. They are letting you know that certain functions from the stats and base packages (which are loaded by default when you start R) are masked by different functions with the same name in the dplyr package. It turns out, the order that you load the packages in matters. Since we loaded dplyr after stats, R will assume that if you call filter(), you mean the dplyr version unless you specify otherwise.\nBeing specific about which version of filter(), for example, you call is easy. To explicitly call a function by its unambiguous name, we use the syntax package_name::function_name(...). So, if we wanted to call the stats version of filter() in this Rmarkdown document, I would use the syntax stats::filter(...).\n\n\n\n\n\n\n\n\nRemove messages and warnings\n\n\n\nMessages and warnings are important, but we might not want them in our final document. After you have read the packages in, adjust the chunk settings in your library chunk to suppress warnings and messages by adding #| message: false or #| warning: false. Both of these chunk options, when set to false, prevents messages or warnings from appearing in the rendered file.\n\n\nNow that we have introduced some data wrangling libraries, let’s get the data that we are going to use for this lesson.\n\n\n\n\n\n\nSetup\n\n\n\n\nGo to KNB Data Package Alaska commercial salmon catches by management region (1886- 1997)\nFind the data file df35b.302.1. Right click the “Download” button and select “Copy Link Address”\nPaste the copied URL into the read_csv() function\n\nThe code chunk you use to read in the data should look something like this:\n\ncatch_original &lt;- read_csv(\"https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1\")\n\nNote for Windows users: Keep in mind, if you want to replicate this workflow in your local computer you also need to use the url() function here with the argument method = \"libcurl\".\nIt would look like this:\n\ncatch_original &lt;- read.csv(url(\"https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1\", method = \"libcurl\"))\n\n\n\nThis data set is relatively clean and easy to interpret as-is. While it may be clean, it’s in a shape that makes it hard to use for some types of analyses so we’ll want to fix that first.\n\n\n\n\n\n\nExercise\n\n\n\nBefore we get too much further, spend a minute or two outlining your Quarto document so that it includes the following sections and steps:\n\nData Sources\n\nRead in the data\nExplore data\n\nClean and Reshape data\n\nUsing select() function\nCheck column types\nReplace values in a column with mutate()\nReshape data with pivot_longer() and pivot_wider()\nRename columns rename()\nAdd columns with mutate()\nSummary stats using group_by() and summarize()\nFiltering rows using filter()\nSort data using arrange()\nSplit and combine values in columns with separate() and unite()",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#data-exploration",
    "href": "s04_r_tidyverse_clean_wrangle.html#data-exploration",
    "title": "Cleaning and Wrangling Data",
    "section": "3 Data exploration",
    "text": "3 Data exploration\nSimilar to what we did in our Literate Analysis lesson, it is good practice to skim through the data you just read in.\nDoing so is important to make sure the data is read as you were expecting and to familiarize yourself with the data.\nSome of the basic ways to explore your data are:\n\n## Prints the column names of my data frame\ncolnames(catch_original)\n\n## First 6 lines of the data frame\nhead(catch_original)\n\n## Summary of each column of data\nsummary(catch_original)\n\n## Prints unique values in a column (in this case, the region)\nunique(catch_original$Region)\n\n## Opens data frame in its own tab to see each row and column of the data (do in console)\nView(catch_original)",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#about-the-pipe-operator",
    "href": "s04_r_tidyverse_clean_wrangle.html#about-the-pipe-operator",
    "title": "Cleaning and Wrangling Data",
    "section": "4 About the pipe (%>%) operator",
    "text": "4 About the pipe (%&gt;%) operator\nBefore we jump into learning tidyr and dplyr, we first need to explain the pipeline operator %&gt;%.\nBoth the tidyr and the dplyr packages use the pipe operator (%&gt;%), which may look unfamiliar. The pipe is a powerful way to efficiently chain together operations. The pipe will take the output of a previous statement, and use it as the input to the next statement.\nSay you want to both filter() out rows of a data set, and select() certain columns.\nInstead of writing:\n\ndf_filtered &lt;- filter(df, ...)\ndf_selected &lt;- select(df_filtered, ...)\n\nYou can write:\n\ndf_cleaned &lt;- df %&gt;% \n    filter(...) %&gt;%\n    select(...)\n\nIf you think of the assignment operator (&lt;-) as reading like “gets”, then the pipe operator would read like “then”.\nSo you might think of the above chunk being translated as:\n\nThe cleaned data frame gets the original data, and then a filter (of the original data), and then a select (of the filtered data).\n\nThe benefits to using pipes are that you don’t have to keep track of (or overwrite) intermediate data frames. The drawbacks are that it can be more difficult to explain the reasoning behind each step, especially when many operations are chained together. It is good to strike a balance between writing efficient code (chaining operations), while ensuring that you are still clearly explaining, both to your future self and others, what you are doing and why you are doing it.\n\n\n\n\n\n\nQuick Tip\n\n\n\nRStudio has a keyboard shortcut for %&gt;%\n\nWindows: Ctrl + Shift + M\nMac: cmd + shift + M",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#selecting-or-removing-columns-using-select",
    "href": "s04_r_tidyverse_clean_wrangle.html#selecting-or-removing-columns-using-select",
    "title": "Cleaning and Wrangling Data",
    "section": "5 Selecting or removing columns using select()",
    "text": "5 Selecting or removing columns using select()\nWe’re ready to go back to our salmon dataset. The first issue is the extra columns All and notesRegCode. Let’s select only the columns we want, and assign this to a variable called catch_data.\n\ncatch_data &lt;- catch_original %&gt;%\n    select(Region, Year, Chinook, Sockeye, Coho, Pink, Chum)\n\nhead(catch_data)\n\n# A tibble: 6 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SSE     1886 0             5     0     0     0\n2 SSE     1887 0           155     0     0     0\n3 SSE     1888 0           224    16     0     0\n4 SSE     1889 0           182    11    92     0\n5 SSE     1890 0           251    42     0     0\n6 SSE     1891 0           274    24     0     0\n\n\nMuch better!\nThe select() function also allows you to say which columns you don’t want, by passing unquoted column names preceded by minus (-) signs:\n\ncatch_data &lt;- catch_original %&gt;%\n    select(-All,-notesRegCode)",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#quality-check",
    "href": "s04_r_tidyverse_clean_wrangle.html#quality-check",
    "title": "Cleaning and Wrangling Data",
    "section": "6 Quality check",
    "text": "6 Quality check\nNow that we have the data we are interested in using, we should do a little quality check to see that everything seems as expected. One nice way of doing this is the glimpse() function.\n\ndplyr::glimpse(catch_data)\n\nRows: 1,708\nColumns: 7\n$ Region  &lt;chr&gt; \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\",…\n$ Year    &lt;dbl&gt; 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 18…\n$ Chinook &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"3\", \"4\", \"5\", \"9…\n$ Sockeye &lt;dbl&gt; 5, 155, 224, 182, 251, 274, 207, 189, 253, 408, 989, 791, 708,…\n$ Coho    &lt;dbl&gt; 0, 0, 16, 11, 42, 24, 11, 1, 5, 8, 192, 161, 132, 139, 84, 107…\n$ Pink    &lt;dbl&gt; 0, 0, 0, 92, 0, 0, 8, 187, 529, 606, 996, 2218, 673, 1545, 204…\n$ Chum    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 1, 2, 0, 0, 0, 102, 343…\n\n\n\n\n\n\n\n\nExercise\n\n\n\nExamine the output of the glimpse() function call. Does anything seem amiss with this data set that might warrant fixing?\n\n\nAnswer:\n\nThe Chinook catch data are character class. Let’s fix it using the function mutate() before moving on.",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#changing-column-content-using-mutate",
    "href": "s04_r_tidyverse_clean_wrangle.html#changing-column-content-using-mutate",
    "title": "Cleaning and Wrangling Data",
    "section": "7 Changing column content using mutate()",
    "text": "7 Changing column content using mutate()\nWe can use the mutate() function to change a column, or to create a new column. First, let’s try to convert the Chinook catch values to numeric type using the as.numeric() function, and overwrite the old Chinook column.\n\ncatch_clean &lt;- catch_data %&gt;%\n    mutate(Chinook = as.numeric(Chinook))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Chinook = as.numeric(Chinook)`.\nCaused by warning:\n! NAs introduced by coercion\n\nhead(catch_clean)\n\n# A tibble: 6 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SSE     1886       0       5     0     0     0\n2 SSE     1887       0     155     0     0     0\n3 SSE     1888       0     224    16     0     0\n4 SSE     1889       0     182    11    92     0\n5 SSE     1890       0     251    42     0     0\n6 SSE     1891       0     274    24     0     0\n\n\nWe get a warning \"NAs introduced by coercion\" which is R telling us that it couldn’t convert every value to an integer and, for those values it couldn’t convert, it put an NA in its place. This is behavior we commonly experience when cleaning data sets and it’s important to have the skills to deal with it when it comes up.\nTo investigate, let’s isolate the issue. We can find out which values are NAs with a combination of is.na() and which(), and save that to a variable called i.\n\ni &lt;- which(is.na(catch_clean$Chinook))\ni\n\n[1] 401\n\n\nIt looks like there is only one problem row, lets have a look at it in the original data.\n\ncatch_data[i,]\n\n# A tibble: 1 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 GSE     1955 I            66     0     0     1\n\n\nWell that’s odd: The value in Chinook is the letter I. It turns out that this data set is from a PDF which was automatically converted into a csv and this value of I is actually a 1.\nLet’s fix it by incorporating the if_else() function to our mutate() call, which will change the value of the Chinook column to 1 if the value is equal to I, then will use as.numeric() to turn the character representations of numbers into numeric typed values.\n\ncatch_clean &lt;- catch_data %&gt;%\n    mutate(Chinook = if_else(condition = Chinook == \"I\", \n                             true = \"1\", \n                             false = Chinook),\n           Chinook = as.numeric(Chinook))\n\n##check\ncatch_clean[i, ]\n\n# A tibble: 1 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 GSE     1955       1      66     0     0     1",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#changing-shape-using-pivot_longer-and-pivot_wider",
    "href": "s04_r_tidyverse_clean_wrangle.html#changing-shape-using-pivot_longer-and-pivot_wider",
    "title": "Cleaning and Wrangling Data",
    "section": "8 Changing shape using pivot_longer() and pivot_wider()",
    "text": "8 Changing shape using pivot_longer() and pivot_wider()\nThe next issue is that the data are in a wide format and we want the data in a long format instead. The function pivot_longer() from the tidyr package helps us do this conversion. If you do not remember all the arguments that go into pivot_longer() you can always call the help page by typing ?pivot_longer in the console.\n\ncatch_long &lt;- catch_clean %&gt;% \n    #pivot longer all columns except Region and Year\n    pivot_longer(\n        cols = -c(Region, Year),\n        names_to = \"species\",\n        values_to = \"catch\"\n    )\n\nhead(catch_long)\n\n# A tibble: 6 × 4\n  Region  Year species catch\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 SSE     1886 Chinook     0\n2 SSE     1886 Sockeye     5\n3 SSE     1886 Coho        0\n4 SSE     1886 Pink        0\n5 SSE     1886 Chum        0\n6 SSE     1887 Chinook     0\n\n\nThe syntax we used above for pivot_longer() might be a bit confusing so let’s walk though it.\n\nThe first argument to pivot_longer is the columns over which we are pivoting. You can select these by listing either the names of the columns you do want to pivot, or in this case, the names of the columns you are not pivoting over.\nThe names_to argument: this is the name of the column that you are creating from the column names of the columns you are pivoting over.\nThe values_to argument: the name of the column that you are creating from the values in the columns you are pivoting over.\n\nThe opposite of pivot_longer() is the pivot_wider() function. It works in a similar declarative fashion:\n\ncatch_wide &lt;- catch_long %&gt;%\n    pivot_wider(names_from = species,\n                values_from = catch)\n\nhead(catch_wide)\n\n# A tibble: 6 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SSE     1886       0       5     0     0     0\n2 SSE     1887       0     155     0     0     0\n3 SSE     1888       0     224    16     0     0\n4 SSE     1889       0     182    11    92     0\n5 SSE     1890       0     251    42     0     0\n6 SSE     1891       0     274    24     0     0\n\n\nSame than we did above we can pull up the documentation of the function to remind ourselves what goes in which argument. Type ?pivot_wider in the console.",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#renaming-columns-with-rename",
    "href": "s04_r_tidyverse_clean_wrangle.html#renaming-columns-with-rename",
    "title": "Cleaning and Wrangling Data",
    "section": "9 Renaming columns with rename()",
    "text": "9 Renaming columns with rename()\nIf you scan through the data, you may notice the values in the catch column are very small (these are supposed to be annual catches). If we look at the metadata we can see that the catch column is in thousands of fish, so let’s convert it before moving on.\nLet’s first rename the catch column to be called catch_thousands:\n\ncatch_long &lt;- catch_long %&gt;%\n    rename(catch_thousands = catch)\n\nhead(catch_long)\n\n# A tibble: 6 × 4\n  Region  Year species catch_thousands\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;\n1 SSE     1886 Chinook               0\n2 SSE     1886 Sockeye               5\n3 SSE     1886 Coho                  0\n4 SSE     1886 Pink                  0\n5 SSE     1886 Chum                  0\n6 SSE     1887 Chinook               0\n\n\n\n\n\n\n\n\nnames() versus rename()\n\n\n\nMany people use the base R function names() to rename columns, often in combination with column indexing that relies on columns being in a particular order. Column indexing is often also used to select columns instead of the select() function from dplyr. Although these methods work just fine, they do have one major drawback: in most implementations they rely on you knowing exactly the column order your data is in.\nTo illustrate why your knowledge of column order isn’t reliable enough for these operations, considering the following scenario:\nYour colleague emails you letting you know that she has an updated version of the conductivity-temperature-depth data from this year’s research cruise, and sends it along. Excited, you re-run your scripts that use this data for your phytoplankton research. You run the script and suddenly all of your numbers seem off. You spend hours trying to figure out what is going on.\nUnbeknownst to you, your colleagues bought a new sensor this year that measures dissolved oxygen. Because of the new variables in the data set, the column order is different. Your script which previously renamed the fourth column, SAL_PSU to salinity now renames the fourth column, O2_MGpL to salinity. No wonder your results looked so weird, good thing you caught it!\nIf you had written your code so that it doesn’t rely on column order, but instead renames columns using the rename() function, the code would have run just fine (assuming the name of the original salinity column didn’t change, in which case the code would have thrown an error in an obvious way). This is an example of a defensive coding strategy, where you try to anticipate issues before they arise, and write your code in such a way as to keep the issues from happening.",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#adding-columns-using-mutate",
    "href": "s04_r_tidyverse_clean_wrangle.html#adding-columns-using-mutate",
    "title": "Cleaning and Wrangling Data",
    "section": "10 Adding columns using mutate()",
    "text": "10 Adding columns using mutate()\nNow let’s use mutate() again to create a new column called catch with units of fish (instead of thousands of fish).\n\ncatch_long &lt;- catch_long %&gt;%\n    mutate(catch = catch_thousands * 1000)\n\nhead(catch_long)\n\nLet’s remove the catch_thousands column for now since we don’t need it. Note that here we have added to the expression we wrote above by adding another function call (mutate) to our expression. This takes advantage of the pipe operator by grouping together a similar set of statements, which all aim to clean up the catch_clean data frame.\n\ncatch_long &lt;- catch_long %&gt;%\n    mutate(catch = catch_thousands * 1000) %&gt;%\n    select(-catch_thousands)\n\nhead(catch_long)\n\n# A tibble: 6 × 4\n  Region  Year species catch\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 SSE     1886 Chinook     0\n2 SSE     1886 Sockeye  5000\n3 SSE     1886 Coho        0\n4 SSE     1886 Pink        0\n5 SSE     1886 Chum        0\n6 SSE     1887 Chinook     0\n\n\nWe’re now ready to start analyzing the data.",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#summary-statistics-using-group_by-and-summarize",
    "href": "s04_r_tidyverse_clean_wrangle.html#summary-statistics-using-group_by-and-summarize",
    "title": "Cleaning and Wrangling Data",
    "section": "11 Summary statistics using group_by() and summarize()",
    "text": "11 Summary statistics using group_by() and summarize()\nSuppose we are now interested in getting the average catch per region. In our initial data exploration we saw there are 18 regions, we can easily see their names again:\n\nunique(catch_original$Region)\n\n [1] \"SSE\" \"NSE\" \"YAK\" \"GSE\" \"BER\" \"COP\" \"PWS\" \"CKI\" \"BRB\" \"KSK\" \"YUK\" \"NRS\"\n[13] \"KTZ\" \"KOD\" \"CHG\" \"SOP\" \"ALU\" \"NOP\"\n\n\nThink about how we would calculate the average catch per region “by hand”. It would be something like this:\n\nWe start with our table and notice there are multiple regions in the “Regions” column.\nWe split our original table to group all observations from the same region together.\nWe calculate the average catch for each of the groups we form.\nThen we combine the values for average catch per region into a single table.\n\n\n\n\n\n\n\n\nAnalyses like this conform to what is known as the Split-Apply-Combine strategy. This strategy follows the three steps we explained above:\n\nSplit: Split the data into logical groups (e.g., region, species, etc.)\nApply: Calculate some summary statistic on each group (e.g. mean catch by year, number of individuals per species)\nCombine: Combine the statistic calculated on each group back together into a single table\n\nThe dplyr library lets us easily employ the Split-Apply-Combine strategy by using the group_by() and summarize() functions:\n\nmean_region &lt;- catch_long %&gt;%\n    group_by(Region) %&gt;%\n    summarize(mean_catch = mean(catch))\n\nhead(mean_region)\n\n# A tibble: 6 × 2\n  Region mean_catch\n  &lt;chr&gt;       &lt;dbl&gt;\n1 ALU        40384.\n2 BER        16373.\n3 BRB      2709796.\n4 CHG       315487.\n5 CKI       683571.\n6 COP       179223.\n\n\nLet’s see how the previous code implements the Split-Apply-Combine strategy:\n\ngroup_by(Region): this is telling R to split the dataframe and create a group for each different value in the column Region. R just keeps track of the groups, it doesn’t return separate dataframes per region.\nmean(catch): here mean is the function we want to apply to the column catch in each group.\nsummarize(catch = mean(catch)) the function summarize() is used to combine the results of mean(catch) in each group into a single table. The argument mean_catch = mean(catch) indicates that the column having the results of mean(catch) will be named mean_catch.\n\nAnother common use of group_by() followed by summarize() is to count the number of rows in each group. We have to use a special function from dplyr, n().\n\nn_region &lt;- catch_long %&gt;%\n    group_by(Region) %&gt;%\n    summarize(n = n())\n\nhead(n_region)\n\n# A tibble: 6 × 2\n  Region     n\n  &lt;chr&gt;  &lt;int&gt;\n1 ALU      435\n2 BER      510\n3 BRB      570\n4 CHG      550\n5 CKI      525\n6 COP      470\n\n\n\n\n\n\n\n\nTry using count()\n\n\n\nIf you are finding that you are reaching for this combination of group_by(), summarize() and n() a lot, there is a helpful dplyr function count() that accomplishes this in one function!\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nFind another grouping and statistic to calculate for each group.\nFind out if you can group by multiple variables.\n\n\n\nAnswer\n## for example:\ncatch_year_sp &lt;- catch_long %&gt;%\n    group_by(Year, species) %&gt;%\n    summarize(total_year = sum(catch, na.rm = T))",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#filtering-rows-using-filter",
    "href": "s04_r_tidyverse_clean_wrangle.html#filtering-rows-using-filter",
    "title": "Cleaning and Wrangling Data",
    "section": "12 Filtering rows using filter()",
    "text": "12 Filtering rows using filter()\nWe use the filter() function to filter our data.frame to rows matching some condition. It’s similar to subset() from base R.\nLet’s go back to our original data.frame and do some filter()ing:\n\nsse_catch &lt;- catch_long %&gt;%\n    filter(Region == \"SSE\")\n\nhead(sse_catch)\n\n# A tibble: 6 × 4\n  Region  Year species catch\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 SSE     1886 Chinook     0\n2 SSE     1886 Sockeye  5000\n3 SSE     1886 Coho        0\n4 SSE     1886 Pink        0\n5 SSE     1886 Chum        0\n6 SSE     1887 Chinook     0\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nFilter to just catches of over one million fish\nFilter to just Chinook from the SSE region\n\n\n\nAnswer\n## Catches over a million fish\ncatch_million &lt;- catch_long %&gt;%\n    filter(catch &gt; 1000000)\n\n## Chinook from SSE data\nchinook_see &lt;- catch_long %&gt;%\n    filter(Region == \"SSE\",\n           species == \"Chinook\")\n\n## OR\nchinook_see &lt;- catch_long %&gt;%\n    filter(Region == \"SSE\" & species == \"Chinook\")",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#sorting-your-data-using-arrange",
    "href": "s04_r_tidyverse_clean_wrangle.html#sorting-your-data-using-arrange",
    "title": "Cleaning and Wrangling Data",
    "section": "13 Sorting your data using arrange()",
    "text": "13 Sorting your data using arrange()\nThe arrange() function is used to sort the rows of a data.frame. Two common cases to use arrange() are:\n\nTo calculate a cumulative sum (with cumsum()) so row order matters\nTo display a table (like in an .qmd document) in sorted order\n\nLet’s re-calculate mean catch by region, and then arrange() the output by mean catch:\n\nmean_region &lt;- catch_long %&gt;%\n    group_by(Region) %&gt;%\n    summarize(mean_catch = mean(catch)) %&gt;%\n    arrange(mean_catch)\n\nhead(mean_region)\n\n# A tibble: 6 × 2\n  Region mean_catch\n  &lt;chr&gt;       &lt;dbl&gt;\n1 BER        16373.\n2 KTZ        18836.\n3 ALU        40384.\n4 NRS        51503.\n5 KSK        67642.\n6 YUK        68646.\n\n\nThe default sorting order of arrange() is to sort in ascending order. To reverse the sort order, wrap the column name inside the desc() function:\n\nmean_region &lt;- catch_long %&gt;%\n    group_by(Region) %&gt;%\n    summarize(mean_catch = mean(catch)) %&gt;%\n    arrange(desc(mean_catch))\n\nhead(mean_region)\n\n# A tibble: 6 × 2\n  Region mean_catch\n  &lt;chr&gt;       &lt;dbl&gt;\n1 SSE      3184661.\n2 BRB      2709796.\n3 NSE      1825021.\n4 KOD      1528350 \n5 PWS      1419237.\n6 SOP      1110942.",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#splitting-a-column-using-separate-and-unite",
    "href": "s04_r_tidyverse_clean_wrangle.html#splitting-a-column-using-separate-and-unite",
    "title": "Cleaning and Wrangling Data",
    "section": "14 Splitting a column using separate() and unite()",
    "text": "14 Splitting a column using separate() and unite()\nThe separate() function allow us to easily split a single column into numerous. Its complement, the unite() function, allows us to combine multiple columns into a single one.\nThis can come in really handy when we need to split a column into two pieces by a consistent separator (like a dash).\nLet’s make a new data.frame with fake data to illustrate this. Here we have a set of site identification codes with information about the island where the site is (the first 3 letters) and a site number (the 3 numbers). If we want to group and summarize by island, we need a column with just the island information.\n\nsites_df &lt;- data.frame(site = c(\"HAW-101\",\n                                \"HAW-103\",\n                                \"OAH-320\",\n                                \"OAH-219\",\n                                \"MAU-039\"))\n\nsites_df %&gt;%\n    separate(site, c(\"island\", \"site_number\"), \"-\")\n\n  island site_number\n1    HAW         101\n2    HAW         103\n3    OAH         320\n4    OAH         219\n5    MAU         039\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSplit the city column in the data frame cities_df into city and state_code columns\n\n## create `cities_df`\ncities_df &lt;- data.frame(city = c(\"Juneau AK\",\n                                 \"Sitka AK\",\n                                 \"Anchorage AK\"))\n\n\n\nAnswer\ncolnames(cities_df)\n\ncities_clean &lt;- cities_df %&gt;%\n    separate(city, c(\"city\", \"state_code\"), \" \")\n\n\n\n\nThe unite() function does just the reverse of separate(). If we have a data.frame that contains columns for year, month, and day, we might want to unite these into a single date column.\n\ndates_df &lt;- data.frame(\n    year = c(\"1930\",\n             \"1930\",\n             \"1930\"),\n    month = c(\"12\",\n              \"12\",\n              \"12\"),\n    day = c(\"14\",\n            \"15\",\n            \"16\")\n)\n\ndates_df %&gt;%\n    unite(date, year, month, day, sep = \"-\")\n\n        date\n1 1930-12-14\n2 1930-12-15\n3 1930-12-16",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "s04_r_tidyverse_clean_wrangle.html#now-all-together",
    "href": "s04_r_tidyverse_clean_wrangle.html#now-all-together",
    "title": "Cleaning and Wrangling Data",
    "section": "15 Now, all together!",
    "text": "15 Now, all together!\nWe just ran through the various things we can do with dplyr and tidyr but if you’re wondering how this might look in a real analysis. Let’s look at that now:\n\ncatch_original &lt;- read_csv(\"https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1\")\n\nmean_region &lt;- catch_original %&gt;%\n  select(-All, -notesRegCode) %&gt;% \n  mutate(Chinook = if_else(Chinook == \"I\", \"1\", Chinook)) %&gt;% \n  mutate(Chinook = as.numeric(Chinook)) %&gt;% \n  pivot_longer(-c(Region, Year), \n               names_to = \"species\", \n               values_to = \"catch\") %&gt;%\n  mutate(catch = catch*1000) %&gt;% \n  group_by(Region) %&gt;% \n  summarize(mean_catch = mean(catch)) %&gt;% \n  arrange(desc(mean_catch))\n\nhead(mean_region)\n\n# A tibble: 6 × 2\n  Region mean_catch\n  &lt;chr&gt;       &lt;dbl&gt;\n1 SSE      3184661.\n2 BRB      2709796.\n3 NSE      1825021.\n4 KOD      1528350 \n5 PWS      1419237.\n6 SOP      1110942.\n\n\nWe have completed our lesson on Cleaning and Wrangling data. Before we break, let’s practice our Git workflow.\n\n\n\n\n\n\nSteps\n\n\n\n\nSave the .qmd you have been working on for this lesson.\nRender the Quarto file. This is a way to test everything in your code is working.\nStage (Add) &gt; Commit &gt; Pull &gt; Push",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "slides/r_programming_introduction/slides.html#title-slide",
    "href": "slides/r_programming_introduction/slides.html#title-slide",
    "title": "Authentic Research Experience for Teachers @ LTERs",
    "section": "",
    "text": "Working with R & RStudio\nAn introduction to programming in R\n\n\nNCEAS Learning Hub coreR May 2025"
  },
  {
    "objectID": "slides/r_programming_introduction/slides.html#welcom-to-r",
    "href": "slides/r_programming_introduction/slides.html#welcom-to-r",
    "title": "Authentic Research Experience for Teachers @ LTERs",
    "section": "",
    "text": "Welcome to programming in R\n\n\nR is a great language to learn data-oriented programming because it is widely adopted, user-friendly, and (most importantly) open source!\n\n\n\n\n\nArtwork by Allison Horst\n\n\n\n\n\nSo what is the difference between R and RStudio?"
  },
  {
    "objectID": "slides/r_programming_introduction/slides.html#r-rstudio",
    "href": "slides/r_programming_introduction/slides.html#r-rstudio",
    "title": "Authentic Research Experience for Teachers @ LTERs",
    "section": "",
    "text": "R vs RStudio\n\n\n\nR is a knife. You have food to prepare, and the knife is one of the tools that you’ll use to accomplish your task. \nRStudio is the kitchen. RStudio provides a place to do your work!"
  },
  {
    "objectID": "slides/r_programming_introduction/slides.html#rstudio-ide",
    "href": "slides/r_programming_introduction/slides.html#rstudio-ide",
    "title": "Authentic Research Experience for Teachers @ LTERs",
    "section": "",
    "text": "RStudio IDE\n\n\nLet’s take a tour of the RStudio interface.\n\n\n\n\n\nQuick Tip: You can change the default location of the panes, among many other things. More information here"
  },
  {
    "objectID": "slides/r_programming_introduction/slides.html#example-code-slide",
    "href": "slides/r_programming_introduction/slides.html#example-code-slide",
    "title": "Authentic Research Experience for Teachers @ LTERs",
    "section": "",
    "text": "Example Code\n\n\nCreating an object\n\n# think of this code as someone saying \"important_value gets 12\".\nimportant_value &lt;- 3*4"
  },
  {
    "objectID": "s01_git_setup.html",
    "href": "s01_git_setup.html",
    "title": "Git and GitHub Setup",
    "section": "",
    "text": "Learning objectives\n\n\n\n\nSet global options in your .gitconfig file\nPractice how to set up GitHub Authentication using a Personal Access Token (PAT)",
    "crumbs": [
      "Git and GitHub Setup"
    ]
  },
  {
    "objectID": "s01_git_setup.html#set-up-global-options-in-git",
    "href": "s01_git_setup.html#set-up-global-options-in-git",
    "title": "Git and GitHub Setup",
    "section": "1 Set up global options in Git",
    "text": "1 Set up global options in Git\nBefore using Git, you need to tell it who you are, also known as setting the global options. You can do this either on the terminal using git command or in the console using the R package usethis. For this lesson we will use the usethis package. However, you can also find the git commands to reference in the future.\n\n\n\n\n\n\nWhat’s the Terminal?\n\n\n\nTechnically, the Terminal is an interface for the shell, a computer program. To put that simply, we use the Terminal to tell a computer what to do. This is different from the Console in RStudio, which interprets R code and returns a value.\nYou can access the terminal through RStudio by clicking Tools &gt; Terminal &gt; New Terminal.\nA Terminal tab should now be open right next to the Console tab.\n\n\n\n\n\n\n\n\nDon’t be afraid to dip your toes in the Terminal\n\n\n\nMost of our Git operations will be done in RStudio, but there are some situations where you must work in the Terminal and use command line. It may be daunting to code in the Terminal, but as your comfort increases over time, you might find you prefer it. Either way, it’s beneficial to learn enough command line and to feel comfortable in the Terminal.\n\n\nTo introduce ourselves to git we are going to use the function usethis::use_git_config(), followed by usethis::git_default_branch_configure(). This will update our global options with our GitHub user name and email information.\nBelow you will find code to do this in the console using functions from the usethis package and the terminal using git commands.\nMake sure to type your exact GitHub username and email associated to your GitHub account.\n\nConsoleTerminal\n\n\nStep 1: set the user’s global user.name and user.email and define integrate changes from one branch into another branch for all repositories.\n\n1usethis::use_git_config(user.name = \"my_user_name\",\n2                        user.email = \"my_email@nceas.ucsb.edu\",\n3                        pull.rebase = \"false\")\n\n\n1\n\nAdd you exact same GitHub user name. Case and spelling matters!\n\n2\n\nSet up your email address associated to you GitHub account.\n\n3\n\nSetting “merge” as the default strategy to integrate changes from one branch into another branch (for all repos). Check the note at the end of this chapter for more details.\n\n\n\n\nStep 2: define the name of the branch that gets created when you make the first commit in a new Git repo\n\nusethis::git_default_branch_configure(name = \"main\")\n\nStep 3: check to make sure everything looks correct\n\nusethis::git_sitrep()\n\n\n\nStep 1: set the user’s global user.name and user.email and define merge strategy for all repositories.\ngit config --global user.name \"my_user_name\"\nPress enter/return.\nNote that if the code ran successfully, it will look like nothing happened. We will check at the end to make sure it worked.\nThen run:\ngit config --global user.email \"my_email@nceas.ucsb.edu\"\nPress enter/return.\nThen run:\ngit config --global pull.rebase false\nStep 2: define the name of the branch that gets created when you make the first commit in a new Git repo.\ngit config --global init.defaultBranch main\nStep 3: check to make sure everything looks correct.\nThe following command return the global options you have set.\ngit config --global --list\n\n\n\n\n\n\n\n\n\n\nCase and spelling matters!\n\n\n\nWhen you add your username and email to the global options you must use the exact same spelling and case that you used on GitHub otherwise, Git won’t be able to sync to your account.\n\n\n\n\n\n\n\n\nWhy set the default branch name to main?\n\n\n\nPreviously, the default branch name was master and this terminology for Git branches invokes motivates us to update our default branch to main instead.\n\n\n\nSet a long timeout for the git cache\nFinally, we will run a step that is only necessary when working on a server. We need to set our credentials to not time out for a very long time. This is related to how our server operating system handles credentials - not doing this will make your Personal Access Token (PAT, which we will set up in the next section) expire after 15 min on the system, even though it is actually valid for at least a month. We will do this configuration in the terminal.\nYou can access the terminal through RStudio by clicking Tools &gt; Terminal &gt; New Terminal.\n\n\n\n\n\n\nTHIS ONLY NEEDS TO BE RUN ON THE SERVER\n\n\n\nDO NOT RUN THE NEXT LINE when setting up Git and GitHub on your Personal Computer\n\n\nBy running the following command we are asking git to store our credential information in the cache for 10 million seconds (almost 4 months).\ngit config --global credential.helper 'cache --timeout=10000000'",
    "crumbs": [
      "Git and GitHub Setup"
    ]
  },
  {
    "objectID": "s01_git_setup.html#github-authentication",
    "href": "s01_git_setup.html#github-authentication",
    "title": "Git and GitHub Setup",
    "section": "2 GitHub Authentication",
    "text": "2 GitHub Authentication\nGitHub recently deprecated password authentication for accessing repositories, so we need to set up a secure way to authenticate.\nThe book Happy Git and GitHub for the useR has a wealth of information related to working with Git in R, and these instructions are based off of Chapter 9 Personal access token for HTTPS.\nWe will be using a Personal Access Token (PAT) in this course. For better security and long term use, we recommend taking the extra steps to set up SSH keys (check out Chapter 10 Set up Keys for SSH).\n\n\n\n\n\n\nSetting up your PAT\n\n\n\n\nRun usethis::create_github_token() in the Console.\nA new browser window should open up to GitHub, showing all the scopes options. You can review the scopes, but you don’t need to worry about which ones to select this time. The previous function automatically pre-selects some recommended scopes. Go ahead and scroll to the bottom and click “Generate Token”.\nCopy the generated token.\nBack in RStudio, run gitcreds::gitcreds_set() in the Console.\nPaste your PAT when the prompt asks for it.\nLast thing, run usethis::git_sitrep() in the Console to check your Git configuration and that you’ve successful stored your PAT. Note: look for Personal access token for 'https://github.com': '&lt;discovered&gt;'\n\nIf you see &lt;unset&gt; instead of &lt;discovered&gt; means your PAT is not correctly set. You need to troubleshoot.\n\n\nCongrats! Now you’ve setup your authentication you should be able to work with GitHub in RStudio now.",
    "crumbs": [
      "Git and GitHub Setup"
    ]
  },
  {
    "objectID": "s01_git_setup.html#strategy-to-integrate-changes-from-one-branch-into-another",
    "href": "s01_git_setup.html#strategy-to-integrate-changes-from-one-branch-into-another",
    "title": "Git and GitHub Setup",
    "section": "3 Strategy to integrate changes from one branch into another",
    "text": "3 Strategy to integrate changes from one branch into another\nAbove we configured our global options for all the repositories you create in your server session to use pull.rebase = \"false\" as the strategy to integrate changes from two branches. With this we are saying to merge changes (as opposed to rebasing).\nIt is important to highlight that this configuration can be repo specific. This mean, you can configure how you want git to reconciling two branches at a repository level and not “for all repositories”. Allowing you to control on how git weaves things in when collaborating with others.\nIf you don’t define pull.rebase = \"false\" when setting the global configurations, you will have to define this for each repository you create. You will likely see the following message after you pull, meaning you have not define how to reconciling two branches in your repository.\n\nTo solve this issues you have to run either of the two suggested strategies on the terminal.\ngit config pull.rebase false\nor\ngit config pull.rebase true",
    "crumbs": [
      "Git and GitHub Setup"
    ]
  },
  {
    "objectID": "s05_r_data_visualization.html",
    "href": "s05_r_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nUnderstand the fundamentals of how the ggplot2 package works\nUse ggplot2’s theme and other customization functions create publication-grade graphics\nIntroduce the leaflet and DT package to create interactive maps and tables respectively",
    "crumbs": [
      "Data Visualization"
    ]
  },
  {
    "objectID": "s05_r_data_visualization.html#overview",
    "href": "s05_r_data_visualization.html#overview",
    "title": "Data Visualization",
    "section": "1 Overview",
    "text": "1 Overview\nggplot2 is a popular package for visualizing data in R. From the home page:\n\nggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.\n\nIt’s been around for years and has pretty good documentation and tons of example code around the web (like on StackOverflow). The goal of this lesson is to explain the fundamentals of how ggplot2 work, introduce useful functions for customizing your plots and inspire you to go and explore this awesome resource for visualizing your data.\n\n\n\n\n\n\nggplot2 vs base graphics in R vs others\n\n\n\nThere are many different ways to plot your data in R. All of them work! However, ggplot2 excels at making complicated plots easy and easy plots simple enough\nBase R graphics (plot(), hist(), etc) can be helpful for simple, quick and dirty plots. ggplot2 can be used for almost everything else.\n\n\nLet’s dive into creating and customizing plots with ggplot2.\n\n\n\n\n\n\nSetup\n\n\n\n\nMake sure you’re in the right project (training_{USERNAME}) and use the Git workflow by Pulling to check for any changes. Then, create a new Quarto document, delete the default text, and save this document.\nLoad the packages we’ll need:\n\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(forcats) # makes working with factors easier\nlibrary(ggplot2)\nlibrary(leaflet) # interactive maps\nlibrary(DT) # interactive tables\nlibrary(scales) # scale functions for visualization\nlibrary(janitor) # expedite cleaning and exploring data\nlibrary(viridis) # colorblind friendly color palette\n\n\nLoad the data directly from the EDI Data Repository: Sacramento-San Joaquin Delta Socioecological Monitoring. Navigate to the link above, scroll down and under Resources, click the “Download” button for the “Socioecological monitoring data”, and save or move it into a folder called data in your repository (you might need to create the folder first). It saves as a file called Socioecological_monitoring_data.csv\n\ndelta_visits_raw &lt;- read_csv(\"data/Socioecological_monitoring_data.csv\")\n\nLearn about the data. For this session we are going to be working with data on Socioecological Monitoring on the Sacramento-San Joaquin Delta. Check out the documentation.\nFinally, let’s explore the data we just read into our working environment.\n\n## Check out column names\n\ncolnames(delta_visits_raw)\n\n## Peak at each column and class\nglimpse(delta_visits_raw)\n\n## From when to when\nrange(delta_visits_raw$Date)\n\n## Which time of day?\nunique(delta_visits_raw$Time_of_Day)",
    "crumbs": [
      "Data Visualization"
    ]
  },
  {
    "objectID": "s05_r_data_visualization.html#getting-the-data-ready",
    "href": "s05_r_data_visualization.html#getting-the-data-ready",
    "title": "Data Visualization",
    "section": "2 Getting the data ready",
    "text": "2 Getting the data ready\nIt is more frequent than not, that we need to do some wrangling before we can plot our data the way we want to. After reading and exploring our data, we’ll put our data wrangling skills to practice to get our data in the desired format.\n\n\n\n\n\n\nSide note on clean column names\n\n\n\njanitor::clean_names() is an awesome function to transform all column names into the same format. The default format for this function is snake_case_format. We highly recommend having clear well formatted column names. It makes your life easier down the line.\nHow it works?\n\ndelta_visits &lt;- delta_visits_raw %&gt;% \n    janitor::clean_names()\n\nAnd that’s it! If we look to the column names of the object delta_visits we can see all the columns are in a lowercase, snake format.\n\ncolnames(delta_visits)\n\n [1] \"eco_restore_approximate_location\" \"reach\"                           \n [3] \"latitude\"                         \"longitude\"                       \n [5] \"date\"                             \"time_of_day\"                     \n [7] \"sm_boat\"                          \"med_boat\"                        \n [9] \"lrg_boat\"                         \"bank_angler\"                     \n[11] \"scientist\"                        \"cars\"                            \n[13] \"notes\"                           \n\n\n\n\nWith the tidy data principles in mind. Is this data tidy?\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\nggplot2 for the most part likes data input to be in a long format (aka “tidy”). So let go ahead and make this data frame long instead of wide. Do you remember the name of the function we can use?\nLet’s refresh our memory on how this function works by accessing the help page. Type ?pivot_long() in the console to see the documentation for this function.\n\nvisits_long &lt;- delta_visits %&gt;% \n    pivot_longer(cols = c(sm_boat, med_boat, lrg_boat, bank_angler, scientist, cars),\n                 names_to = \"visitor_type\",\n                 values_to = \"quantity\") %&gt;%\n    rename(restore_loc = eco_restore_approximate_location) %&gt;% \n    select(-notes)\n\n## Checking the outcome\nhead(visits_long)\n\n# A tibble: 6 × 8\n  restore_loc   reach     latitude longitude date       time_of_day visitor_type\n  &lt;chr&gt;         &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt;       \n1 Decker Island Brannan …     38.1     -122. 2017-07-07 unknown     sm_boat     \n2 Decker Island Brannan …     38.1     -122. 2017-07-07 unknown     med_boat    \n3 Decker Island Brannan …     38.1     -122. 2017-07-07 unknown     lrg_boat    \n4 Decker Island Brannan …     38.1     -122. 2017-07-07 unknown     bank_angler \n5 Decker Island Brannan …     38.1     -122. 2017-07-07 unknown     scientist   \n6 Decker Island Brannan …     38.1     -122. 2017-07-07 unknown     cars        \n# ℹ 1 more variable: quantity &lt;dbl&gt;\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\n\n\n\n\nCalculate the daily visits by restore_loc, date, and visitor_type.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\ndaily_visits_loc &lt;- visits_long %&gt;%\n    group_by(restore_loc, date, visitor_type) %&gt;% \n    summarise(daily_visits = sum(quantity))\n    \nhead(daily_visits_loc)\n\n# A tibble: 6 × 4\n# Groups:   restore_loc, date [1]\n  restore_loc   date       visitor_type daily_visits\n  &lt;chr&gt;         &lt;date&gt;     &lt;chr&gt;               &lt;dbl&gt;\n1 Decker Island 2017-07-07 bank_angler             4\n2 Decker Island 2017-07-07 cars                    0\n3 Decker Island 2017-07-07 lrg_boat                0\n4 Decker Island 2017-07-07 med_boat                6\n5 Decker Island 2017-07-07 scientist               0\n6 Decker Island 2017-07-07 sm_boat                 0\n\n\nThe chunk above uses some of the dplyr functions that we’ve used in the past. We use group_by() to indicate that we want to calculate our results for the unique combinations of type of visit, restoration location proximity, and day. We next use summarise() to calculate an daily visit value for each of these groups. Note we use the %in% operator to pipe in the result of one command as an argument to the next one.",
    "crumbs": [
      "Data Visualization"
    ]
  },
  {
    "objectID": "s05_r_data_visualization.html#plotting-with-ggplot2",
    "href": "s05_r_data_visualization.html#plotting-with-ggplot2",
    "title": "Data Visualization",
    "section": "3 Plotting with ggplot2",
    "text": "3 Plotting with ggplot2\n\n3.1 Essential components\nFirst, we’ll cover some ggplot2 basics to create the foundation of our plot. Then, we’ll add on to make our great customized data visualization.\n\n\n\n\n\n\nThe basics\n\n\n\n\nIndicate we are using ggplot() (call the ggplot2::ggplot() function)\nWhat data do we want to plot? (data = my_data)\nWhat are the mapping aesthetics? What variables do we want to plot? (define usingaes() function)\nDefine the geometry of our plot. This specifies the type of plot we’re making (use geom_*() to indicate the type of plot e.g: point, bar, etc.)\n\nNote To add layers to our plot, for example, additional geometries/aesthetics and theme elements or any ggplot object we use +.\n\n\nNow, let’s plot total daily visits by restoration location. We will show this by creating the same plot in 3 slightly different ways. Each of the options below have the 4 essential pieces of a ggplot.\n## Option 1 - data and mapping called in the ggplot() function\nggplot(data = daily_visits_loc,\n       aes(x = restore_loc, y = daily_visits)) +\n    geom_col()\n\n\n## Option 2 - data called in ggplot function; mapping called in geom\nggplot(data = daily_visits_loc) +\n    geom_col(aes(x = restore_loc, y = daily_visits))\n\n\n## Option 3 - data and mapping called in geom\nggplot() +\n    geom_col(data = daily_visits_loc,\n             aes(x = restore_loc, y = daily_visits))\nThey all will create the same plot:\n(Apologies for the jumbled text on the x-axis, we will learn how to make this look better soon)\nggplot(data = daily_visits_loc,\n       aes(x = restore_loc, y = daily_visits)) +\n    geom_col()\n\n\n3.2 Looking at different geoms_*\nHaving the basic structure with the essential components in mind, we can easily change the type of graph by updating the geom_*().\n\n\n\n\n\n\nggplot2 and the pipe operator\n\n\n\nJust like in dplyr and tidyr, we can also pipe a data.frame directly into the first argument of the ggplot function using the %&gt;% operator.\nThis can certainly be convenient, but use it carefully! Combining too many data-tidying or subsetting operations with your ggplot call can make your code more difficult to debug and understand.\n\n\nWe will use the pipe operator to pass into ggplot() a filtered version of daily_visits_loc, and make a plot with different geometries.\nBoxplot Note: These examples are to demonstrate case uses of wrangling function prior to plotting. They are not necessarily plotting best practices.\n\ndaily_visits_loc %&gt;%\n    separate(date, c(\"year\", \"month\", \"day\"), sep = \"-\") %&gt;%\n    filter(daily_visits &lt; 30,\n           visitor_type %in% c(\"sm_boat\", \"med_boat\", \"lrg_boat\")) %&gt;%\n    ggplot(aes(x = visitor_type, y = daily_visits)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\nViolin plot\n\ndaily_visits_loc %&gt;%\n    separate(date, c(\"year\", \"month\", \"day\"), sep = \"-\") %&gt;%\n    filter(daily_visits &lt; 30,\n           visitor_type %in% c(\"sm_boat\", \"med_boat\", \"lrg_boat\")) %&gt;%\n    ggplot(aes(x = visitor_type, y = daily_visits)) +\n    geom_violin()\n\n\n\n\n\n\n\n\nLine and point\n\ndaily_visits_loc %&gt;%\n    filter(restore_loc == \"Decker Island\",\n           visitor_type == \"med_boat\") %&gt;%\n    ggplot(aes(x = date, y = daily_visits)) +\n    geom_line() +\n    geom_point()\n\n\n\n\n\n\n\n\n\n\n3.3 Customizing our plot\nLet’s go back to our base bar graph. What if we want our bars to be blue instead of gray? You might think we could run this:\n\nggplot(data = daily_visits_loc,\n       aes(x = restore_loc, y = daily_visits,\n           fill = \"blue\")) +\n    geom_col()\n\n\n\n\n\n\n\n\nWhy did that happen?\nNotice that we tried to set the fill color of the plot inside the mapping aesthetic call. What we have done, behind the scenes, is create a column filled with the word “blue” in our data frame, and then mapped it to the fill aesthetic, which then chose the default fill color, salmon.\nWhat we really wanted to do was just change the color of the bars. If we want do do that, we can call the color option in the geom_col() function, outside of the mapping aesthetics function call.\n\nggplot(data = daily_visits_loc,\n       aes(x = restore_loc, y = daily_visits)) +\n    geom_col(fill = \"blue\")\n\n\n\n\n\n\n\n\nWhat if we did want to map the color of the bars to a variable, such as visitor_type. ggplot() is really powerful because we can easily get this plot to visualize more aspects of our data.\n\nggplot(data = daily_visits_loc,\n       aes(x = restore_loc, y = daily_visits,\n           fill = visitor_type)) +\n    geom_col()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeep in mind\n\n\n\n\nIf you want to map a variable onto a graph aesthetic (e.g., point color should be based on a specific region), put it within aes().\nIf you want to update your plot base with a constant (e.g. “Make ALL the points BLUE”), you can add the information directly to the relevant geom_ layer outside the aes() call.\n\n\n\n\n3.3.1 Setting ggplot themes\nWe have successfully plotted our data. But, this is clearly not a nice plot. Let’s work on making this plot look a bit nicer. We are going to:\n\nAdd a title, subtitle and adjust labels using labs()\nFlip the x and y axis to make it a sideways column plot and make the labels easier to read\nInclude a built in theme using theme_bw()\n\n\nggplot(data = daily_visits_loc,\n       aes(y = restore_loc, x = daily_visits, fill = visitor_type)) +\n    geom_col() +\n    labs(x = \"Number of Visits\",\n         y = \"Restoration Location\",\n         fill = \"Type of Visitor\",\n         title = \"Total Number of Visits to Delta Restoration Areas by visitor type\",\n         subtitle = \"Sum of all visits during July 2017 and March 2018\") +\n    theme_bw()\n\n\n\n\n\n\n\n\nYou can see that the theme_bw() function changed a lot of the aspects of our plot! The background is white, the grid is a different color, etc. There are lots of other built in themes like this that come with the ggplot2 package that help quickly set the look of the plot. Use the RStudio auto-complete theme_ &lt;TAB&gt; to view a list of theme functions.\n\n## Useful baseline themes are\ntheme_minimal()\ntheme_light()\ntheme_classic()\n\nThe built in theme functions (theme_*()) change the default settings for many elements that can also be changed individually using thetheme() function. The theme() function is a way to further fine-tune the look of your plot. This function takes MANY arguments (just have a look at ?theme). Luckily there are many great ggplot resources online so we don’t have to remember all of these, just Google “ggplot cheat sheet” and find one you like.\nLet’s look at an example of a theme() call, where we change the position of the legend from the right side to the bottom, and remove the ticks of our Locations axis.\n\nggplot(data = daily_visits_loc,\n       aes(y = restore_loc, x = daily_visits, fill = visitor_type)) +\n    geom_col() +\n    labs(x = \"Number of Visits\",\n         y = \"Restoration Location\",\n         fill = \"Type of Visitor\",\n         title = \"Total Number of Visits to Delta Restoration Areas by visitor type\",\n         subtitle = \"Sum of all visits during study period\") +\n    theme_bw() +\n    theme(legend.position = \"bottom\",\n          axis.ticks.y = element_blank()) \n\n\n\n\n\n\n\n\nNote that the theme() call needs to come after any built-in themes like theme_bw() are used. Otherwise, theme_bw() will likely override any theme elements that you changed using theme().\nYou can also save the result of a series of theme() function calls to an object to use on multiple plots. This prevents needing to copy paste the same lines over and over again!\n\nmy_theme &lt;- theme_bw(base_size = 16) +\n    theme(legend.position = \"bottom\",\n          axis.ticks.y = element_blank())\n\nSo now our code will look like this:\n\nggplot(data = daily_visits_loc,\n       aes(y = restore_loc, x = daily_visits, fill = visitor_type)) +\n    geom_col() +\n    labs(x = \"Number of Visits\",\n         y = \"Restoration Location\",\n         fill = \"Type of Visitor\",\n         title = \"Total Number of Visits to Delta Restoration Areas by visitor type\",\n         subtitle = \"Sum of all visits during study period\") +\n    my_theme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\n\n\nWhat changes do you expect to see in your plot by adding the following line of code? Discuss with your neighbor and then try it out!\nscale_x_continuous(breaks = seq(0,120, 20))\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nggplot(data = daily_visits_loc,\n       aes(y = restore_loc, x = daily_visits, fill = visitor_type)) +\n    geom_col() +\n    labs(x = \"Number of Visits\",\n         y = \"Restoration Location\",\n         fill = \"Type of Visitor\",\n         title = \"Total Number of Visits to Delta Restoration Areas by visitor type\",\n         subtitle = \"Sum of all visits during study period\") +\n    scale_x_continuous(breaks = seq(0,120, 20)) +\n    my_theme\n\n\n\n\n\n\n\n\n\n\n\n\nFinally we are going to expand the bars all the way to the axis line. In other words, remove the gap between the bars and the vertical “x-axis” line.\n\nggplot(data = daily_visits_loc,\n       aes(y = restore_loc, x = daily_visits, fill = visitor_type)) +\n    geom_col() +\n    labs(x = \"Number of Visits\",\n         y = \"Restoration Location\",\n         fill = \"Type of Visitor\",\n         title = \"Total Number of Visits to Delta Restoration Areas by visitor type\",\n         subtitle = \"Sum of all visits during study period\") +\n    scale_x_continuous(breaks = seq(0,120, 20), expand = c(0,0)) +\n    my_theme\n\n\n\n\n\n\n\n\n\n3.3.2 Reordering things\nggplot() loves putting things in alphabetical order. But more frequently than not, that’s not the order you actually want things to be plotted. One way to do this is to use the fct_reorder() function from the forcats package. forcats provides tools for working with categorical variables. In this case, we want to reorder our categorical variable of restore_loc based on the total number of visits.\nThe first thing we need to do is to add a column to our data with the total number of visits by location. This will be our “sorting” variable. Then we use fct_reorder() to reorder the restore_loc variable according to our sorting variable.\n\ndaily_visits_totals &lt;- daily_visits_loc %&gt;% \n    group_by(restore_loc) %&gt;%\n    mutate(n = sum(daily_visits)) %&gt;% \n    ungroup() %&gt;%\n    mutate(restore_loc = fct_reorder(restore_loc, n))\n\nhead(daily_visits_totals)\n\n# A tibble: 6 × 5\n  restore_loc   date       visitor_type daily_visits     n\n  &lt;fct&gt;         &lt;date&gt;     &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n1 Decker Island 2017-07-07 bank_angler             4    37\n2 Decker Island 2017-07-07 cars                    0    37\n3 Decker Island 2017-07-07 lrg_boat                0    37\n4 Decker Island 2017-07-07 med_boat                6    37\n5 Decker Island 2017-07-07 scientist               0    37\n6 Decker Island 2017-07-07 sm_boat                 0    37\n\nlevels(daily_visits_totals$restore_loc) ### not alphabetical any more!\n\n [1] \"Sherman Island\"           \"Wildlands\"               \n [3] \"SJ River\"                 \"Twitchell Island\"        \n [5] \"SW Suisun Marsh\"          \"Decker Island\"           \n [7] \"Honker Bay/Chipps Island\" \"North Delta\"             \n [9] \"Grizzly Bay\"              \"Prospect\"                \n\n\nNext, we will run the code for our plot adding the fct_reorder() function.\n\nggplot(data = daily_visits_totals,\n       aes(x = daily_visits, y = restore_loc,\n           fill = visitor_type)) +\n    geom_col() +\n    labs(x = \"Number of Visits\",\n         y = \"Restoration Location\",\n         fill = \"Type of Visitor\",\n         title = \"Total Number of Visits to Delta Restoration Areas by visitor type\",\n         subtitle = \"Sum of all visits during study period\") +\n    scale_x_continuous(breaks = seq(0,120, 20), expand = c(0,0)) +\n    my_theme\n\n\n\n\n\n\n\n\nWhat if you want to plot the other way around? In this case from least to greater? We add the desc() to the variable we are sorting by.\n\ndaily_visits_totals &lt;- daily_visits_loc %&gt;% \n    group_by(restore_loc) %&gt;%\n    mutate(n = sum(daily_visits)) %&gt;% \n    ungroup() %&gt;%\n    mutate(restore_loc = fct_reorder(restore_loc, desc(n)))\n\nggplot(data = daily_visits_totals,\n       aes(x = daily_visits, y = restore_loc,\n           fill = visitor_type)) +\n    geom_col() +\n    labs(x = \"Number of Visits\",\n         y = \"Restoration Location\",\n         fill = \"Type of Visitor\",\n         title = \"Total Number of Visits to Delta Restoration Areas by visitor type\",\n         subtitle = \"Sum of all visits during study period\") +\n    scale_x_continuous(breaks = seq(0,120, 20), expand = c(0,0)) +\n    my_theme\n\n\n\n\n\n\n\n\n\n\n3.3.3 Colors\nThe last thing we will do to our plot is change the color. To do this we are going to use a function from the viridis package. This package provides different color palettes that are designed to improve graph readability for readers with common forms of color blindness and/or color vision deficiency. With viridis, there are multiple other color palette packages or color palettes out there that you can use to customize your graphs. We could spend a whole session talking about colors in R! For the purpose of this lesson we are just going to keep it brief and show one function of the viridis package that will make our plot colors look better.\n\nggplot(data = daily_visits_totals,\n       aes(x = daily_visits, y = restore_loc,\n           fill = visitor_type)) +\n    geom_col() +\n    scale_fill_viridis_d() +\n    labs(x = \"Number of Visits\",\n         y = \"Restoration Location\",\n         fill = \"Type of Visitor\",\n         title = \"Total Number of Visits to Delta Restoration Areas by visitor type\",\n         subtitle = \"Sum of all visits during study period\") +\n    scale_x_continuous(breaks = seq(0,120, 20), expand = c(0,0)) +\n    my_theme\n\n\n\n\n\n\n\n\nThings to keep in mind when choosing a color palette are the number of variables you have and how many colors your palette has. And if you need a discrete or a continuous color palette. Find more information about colors in this R color cheatsheet.\n\n\n3.3.4 Saving plots\nSaving plots using ggplot is easy! The ggsave() function will save either the last plot you created, or any plot that you have saved to an object. You can specify what output format you want, size, resolution, etc. See ?ggsave() for documentation.\nFor example, if we want to save our current plot to an existing folder named “figures”, we can do this:\nggsave(\"figures/visit_restore_site_delta.jpg\", width = 12, height = 6, units = \"in\")\n\n\n3.3.5 Creating multiple plots\nAn easy way to plot another aspect of your data is using the function facet_wrap(). This function takes a mapping to a variable using the syntax ~{variable_name}. The ~ (tilde) is a model operator which tells facet_wrap() to model each unique value within variable_name to a facet in the plot.\nThe default behavior of facet wrap is to put all facets on the same x and y scale. You can use the scales argument to specify whether to allow different scales between facet plots (e.g scales = \"free_y\" to free the y axis scale). You can also specify the number of columns using the ncol = argument or number of rows using nrow =.\n\nfacet_plot &lt;- ggplot(data = daily_visits_totals,\n       aes(x = visitor_type, y = daily_visits,\n           fill = visitor_type)) +\n    geom_col() +\n    facet_wrap(~restore_loc,\n               scales = \"free_y\",\n               ncol = 5,\n               nrow = 2) +\n    scale_fill_viridis_d() +\n    labs(x = \"Type of visitor\",\n         y = \"Number of Visits\",\n         title = \"Total Number of Visits to Delta Restoration Areas\",\n         subtitle = \"Sum of all visits during study period\") +\n    theme_bw() +\n    theme(legend.position = \"bottom\",\n          axis.ticks.x = element_blank(),\n          axis.text.x = element_blank())\n\nfacet_plot\n\n\n\n\n\n\n\n\nWe can save this plot to our figures folder too. Note that this time we are specifically mentioning the object we want to save.\nggsave(\"figures/visit_restore_site_facet.jpg\", plot = facet_plot, width = 12, height = 8, units = \"in\")\n\n\n\n4 Interactive visualization\n\n4.1 Tables with DT\nNow that we know how to make great static visualizations, let’s introduce two other packages that allow us to display our data in interactive ways. These packages really shine when used with GitHub Pages, so at the end of this lesson we will publish our figures to the website we created earlier.\nFirst let’s show an interactive table of unique sampling locations using DT. We will start by creating a data.frame containing unique sampling locations.\n\nlocations &lt;- visits_long %&gt;%\n    distinct(restore_loc, .keep_all = T) %&gt;%\n    select(restore_loc, latitude, longitude)\n\nhead(locations)\n\n# A tibble: 6 × 3\n  restore_loc     latitude longitude\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;\n1 Decker Island       38.1     -122.\n2 SW Suisun Marsh     38.2     -122.\n3 Grizzly Bay         38.1     -122.\n4 Prospect            38.2     -122.\n5 SJ River            38.1     -122.\n6 Wildlands           38.3     -122.\n\n\nThe dplyr::distinct() function comes pretty handy when you want to filter unique values in a column. In this case we use the .keep_all = T argument to keep all the columns of our data frame so we can have the latitude and longitude of each of the locations. If we don’t add this argument, we would end up with a data frame with only one column: restore_loc and 10 rows, one for each of the unique locations.\nNow we can display this table as an interactive table using datatable() from the DT package.\n\ndatatable(locations)\n\n\n\n\n\n\n\n4.2 Maps with leaflet\nThe leaflet() package allows you to make basic interactive maps using just a couple lines of code. Note that unlike ggplot2, the leaflet package uses pipe operators (%&gt;%) and not the additive operator (+).\nThe addTiles() function without arguments will add base tiles to your map from OpenStreetMap. addMarkers() will add a marker at each location specified by the latitude and longitude arguments. Note that the ~ symbol is used here to model the coordinates to the map (similar to facet_wrap() in ggplot).\n\nleaflet(locations) %&gt;%\n    addTiles() %&gt;%\n    addMarkers(\n        lng = ~ longitude,\n        lat = ~ latitude,\n        popup = ~ restore_loc\n    )\n\n\n\n\n\n\nYou can also use leaflet to import Web Map Service (WMS) tiles. For example, we can use any of the base maps provided by USGS in the National Map archive. For example, let’s use the USGSTopo base map. In this example, we also demonstrate how to create a more simple circle marker, the look of which is explicitly set using a series of style-related arguments.\n\nleaflet(locations) %&gt;%\n    addWMSTiles(\n        \"https://basemap.nationalmap.gov/arcgis/services/USGSTopo/MapServer/WmsServer\",\n        layers = \"0\",\n        options = WMSTileOptions(format = \"image/png\", transparent = TRUE)) %&gt;%\n    addCircleMarkers(\n        lng = ~ longitude,\n        lat = ~ latitude,\n        popup = ~ restore_loc,\n        radius = 5,\n        # set fill properties\n        fillColor = \"salmon\",\n        fillOpacity = 1,\n        # set stroke properties\n        stroke = T,\n        weight = 0.5,\n        color = \"white\",\n        opacity = 1)\n\n\n\n\n\n\nWe can also layer base maps. In this case the USGSImageryTopo base map with the USGSHydroCached base map. Note that the url where the map is retrieved is very similar for each USGS base map.\n\nleaflet(locations) %&gt;%\n    addWMSTiles(\n        \"https://basemap.nationalmap.gov/arcgis/services/USGSImageryTopo/MapServer/WmsServer\",\n        layers = \"0\",\n        options = WMSTileOptions(format = \"image/png\", transparent = TRUE)) %&gt;%\n    addWMSTiles(\n        \"https://basemap.nationalmap.gov/arcgis/services/USGSHydroCached/MapServer/WmsServer\",\n        layers = \"0\",\n        options = WMSTileOptions(format = \"image/png\", transparent = TRUE)) %&gt;%\n    addCircleMarkers(\n        lng = ~ longitude,\n        lat = ~ latitude,\n        popup = ~ restore_loc,\n        radius = 5,\n        # set fill properties\n        fillColor = \"salmon\",\n        fillOpacity = 1,\n        # set stroke properties\n        stroke = T,\n        weight = 0.5,\n        color = \"white\",\n        opacity = 1)\n\n\n\n\n\n\nLeaflet has a ton of functionality that can enable you to create some beautiful, functional maps with relative ease. Here is an example of some we created as part of the State of Alaskan Salmon and People (SASAP) project, created using the same tools we showed you here. This map hopefully gives you an idea of how powerful the combination of Quarto or RMarkdown and GitHub Pages can be.\n\n\n\n5 Publish the Data Visualization lesson to your webpage\n\n\n\n\n\n\nSteps\n\n\n\n\nSave the qmd you have been working on for this lesson.\n“Render” the qmd. This is a good way to test if everything in your code is working.\nGo to your index.qmd and the link to the html file with this lesson’s content.\nSave and render index.qmd to an html.\nUse the Git workflow: Stage &gt; Commit &gt; Pull &gt; Push\n\n\n\n\n\n6 ggplot2 Resources\n\nWhy not to use two axes, and what to use instead: The case against dual axis charts by Lisa Charlotte Rost.\nCustomized Data Visualization in ggplot2 by Allison Horst.\nA ggplot2 tutorial for beautiful plotting in R by Cedric Scherer.",
    "crumbs": [
      "Data Visualization"
    ]
  },
  {
    "objectID": "s05_r_data_visualization.html#interactive-visualization",
    "href": "s05_r_data_visualization.html#interactive-visualization",
    "title": "Data Visualization",
    "section": "4 Interactive visualization",
    "text": "4 Interactive visualization\n\n4.1 Tables with DT\nNow that we know how to make great static visualizations, let’s introduce two other packages that allow us to display our data in interactive ways. These packages really shine when used with GitHub Pages, so at the end of this lesson we will publish our figures to the website we created earlier.\nFirst let’s show an interactive table of unique sampling locations using DT. We will start by creating a data.frame containing unique sampling locations.\n\nlocations &lt;- visits_long %&gt;%\n    distinct(restore_loc, .keep_all = T) %&gt;%\n    select(restore_loc, latitude, longitude)\n\nhead(locations)\n\n# A tibble: 6 × 3\n  restore_loc     latitude longitude\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;\n1 Decker Island       38.1     -122.\n2 SW Suisun Marsh     38.2     -122.\n3 Grizzly Bay         38.1     -122.\n4 Prospect            38.2     -122.\n5 SJ River            38.1     -122.\n6 Wildlands           38.3     -122.\n\n\nThe dplyr::distinct() function comes pretty handy when you want to filter unique values in a column. In this case we use the .keep_all = T argument to keep all the columns of our data frame so we can have the latitude and longitude of each of the locations. If we don’t add this argument, we would end up with a data frame with only one column: restore_loc and 10 rows, one for each of the unique locations.\nNow we can display this table as an interactive table using datatable() from the DT package.\n\ndatatable(locations)\n\n\n\n\n\n\n\n4.2 Maps with leaflet\nThe leaflet() package allows you to make basic interactive maps using just a couple lines of code. Note that unlike ggplot2, the leaflet package uses pipe operators (%&gt;%) and not the additive operator (+).\nThe addTiles() function without arguments will add base tiles to your map from OpenStreetMap. addMarkers() will add a marker at each location specified by the latitude and longitude arguments. Note that the ~ symbol is used here to model the coordinates to the map (similar to facet_wrap() in ggplot).\n\nleaflet(locations) %&gt;%\n    addTiles() %&gt;%\n    addMarkers(\n        lng = ~ longitude,\n        lat = ~ latitude,\n        popup = ~ restore_loc\n    )\n\n\n\n\n\n\nYou can also use leaflet to import Web Map Service (WMS) tiles. For example, we can use any of the base maps provided by USGS in the National Map archive. For example, let’s use the USGSTopo base map. In this example, we also demonstrate how to create a more simple circle marker, the look of which is explicitly set using a series of style-related arguments.\n\nleaflet(locations) %&gt;%\n    addWMSTiles(\n        \"https://basemap.nationalmap.gov/arcgis/services/USGSTopo/MapServer/WmsServer\",\n        layers = \"0\",\n        options = WMSTileOptions(format = \"image/png\", transparent = TRUE)) %&gt;%\n    addCircleMarkers(\n        lng = ~ longitude,\n        lat = ~ latitude,\n        popup = ~ restore_loc,\n        radius = 5,\n        # set fill properties\n        fillColor = \"salmon\",\n        fillOpacity = 1,\n        # set stroke properties\n        stroke = T,\n        weight = 0.5,\n        color = \"white\",\n        opacity = 1)\n\n\n\n\n\n\nWe can also layer base maps. In this case the USGSImageryTopo base map with the USGSHydroCached base map. Note that the url where the map is retrieved is very similar for each USGS base map.\n\nleaflet(locations) %&gt;%\n    addWMSTiles(\n        \"https://basemap.nationalmap.gov/arcgis/services/USGSImageryTopo/MapServer/WmsServer\",\n        layers = \"0\",\n        options = WMSTileOptions(format = \"image/png\", transparent = TRUE)) %&gt;%\n    addWMSTiles(\n        \"https://basemap.nationalmap.gov/arcgis/services/USGSHydroCached/MapServer/WmsServer\",\n        layers = \"0\",\n        options = WMSTileOptions(format = \"image/png\", transparent = TRUE)) %&gt;%\n    addCircleMarkers(\n        lng = ~ longitude,\n        lat = ~ latitude,\n        popup = ~ restore_loc,\n        radius = 5,\n        # set fill properties\n        fillColor = \"salmon\",\n        fillOpacity = 1,\n        # set stroke properties\n        stroke = T,\n        weight = 0.5,\n        color = \"white\",\n        opacity = 1)\n\n\n\n\n\n\nLeaflet has a ton of functionality that can enable you to create some beautiful, functional maps with relative ease. Here is an example of some we created as part of the State of Alaskan Salmon and People (SASAP) project, created using the same tools we showed you here. This map hopefully gives you an idea of how powerful the combination of Quarto or RMarkdown and GitHub Pages can be.",
    "crumbs": [
      "Data Visualization"
    ]
  },
  {
    "objectID": "s05_r_data_visualization.html#publish-the-data-visualization-lesson-to-your-webpage",
    "href": "s05_r_data_visualization.html#publish-the-data-visualization-lesson-to-your-webpage",
    "title": "Data Visualization",
    "section": "5 Publish the Data Visualization lesson to your webpage",
    "text": "5 Publish the Data Visualization lesson to your webpage\n\n\n\n\n\n\nSteps\n\n\n\n\nSave the qmd you have been working on for this lesson.\n“Render” the qmd. This is a good way to test if everything in your code is working.\nGo to your index.qmd and the link to the html file with this lesson’s content.\nSave and render index.qmd to an html.\nUse the Git workflow: Stage &gt; Commit &gt; Pull &gt; Push",
    "crumbs": [
      "Data Visualization"
    ]
  },
  {
    "objectID": "s05_r_data_visualization.html#ggplot2-resources",
    "href": "s05_r_data_visualization.html#ggplot2-resources",
    "title": "Data Visualization",
    "section": "6 ggplot2 Resources",
    "text": "6 ggplot2 Resources\n\nWhy not to use two axes, and what to use instead: The case against dual axis charts by Lisa Charlotte Rost.\nCustomized Data Visualization in ggplot2 by Allison Horst.\nA ggplot2 tutorial for beautiful plotting in R by Cedric Scherer.",
    "crumbs": [
      "Data Visualization"
    ]
  },
  {
    "objectID": "index.html#nceas-expertise",
    "href": "index.html#nceas-expertise",
    "title": "About the course",
    "section": "1 NCEAS Expertise",
    "text": "1 NCEAS Expertise\nThe National Center for Ecological Analysis and Synthesis (NCEAS), a research affiliate of UCSB, is a leading expert on interdisciplinary data science and works collaboratively to answer the world’s largest and most complex questions. The NCEAS approach leverages existing data and employs a team science philosophy to squeeze out all potential insights and solutions efficiently - this is called synthesis science.\nNCEAS has 30 years of success with this model among working groups and environmental professionals. Together with the Long Term Ecological Research Network (LTER Network) we are excited to pass along skills, workflows, mindsets learned throughout the years through the Authentic Research Experience for Teachers program.\n\n\n\n\n\n\nLearning Objectives\n\n\n\n\nUnderstand how any why to use Git and GitHub for file management and version control\nUnderstand how and why to use R, RStudio, and Quarto to communicate reproducible scientific analysis",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#setup-for-course-get-the-software",
    "href": "index.html#setup-for-course-get-the-software",
    "title": "About the course",
    "section": "2 Setup for course: get the software!",
    "text": "2 Setup for course: get the software!\nFollow the instructions here to install the needed software and get an account on GitHub.\n\nGit version control software\nGitHub web-based version control system\nR statistical software\nRStudio software to make it easier to work with R (an integrated development environment or IDE)",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#code-of-conduct",
    "href": "index.html#code-of-conduct",
    "title": "About the course",
    "section": "3 Code of Conduct",
    "text": "3 Code of Conduct\nBy participating in this activity you agree to abide by the NCEAS Code of Conduct.",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "About the course",
    "section": "4 About this book",
    "text": "4 About this book\nThese written materials are the result of a continuous and collaborative effort at NCEAS to help researchers make their work more transparent and reproducible. This work began in the early 2000’s, and reflects the expertise and diligence of many, many individuals. The primary authors are listed in the citation below, with additional contributors recognized for their role in developing previous iterations of these or similar materials.\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nThis is a Quarto book. To learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "s02_github_introduction.html",
    "href": "s02_github_introduction.html",
    "title": "Git and GitHub",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nApply the principles of Git to track and manage changes of a project\nUtilize the Git workflow including pulling changes, staging modified files, committing changes, pulling again to incorporate remote changes, and pushing changes to a remote repository\nCreate and configure Git repositories using different workflows",
    "crumbs": [
      "Git and GitHub"
    ]
  },
  {
    "objectID": "s02_github_introduction.html#introduction-to-version-control",
    "href": "s02_github_introduction.html#introduction-to-version-control",
    "title": "Git and GitHub",
    "section": "1 Introduction to Version Control",
    "text": "1 Introduction to Version Control\n\n\n\n\n\nEvery file in the scientific process changes. Manuscripts are edited. Figures get revised. Code gets fixed when bugs are discovered. Sometimes those fixes lead to even more bugs, leading to more changes in the code base. Data files get combined together. Sometimes those same files are split and combined again. In just one research project, we can expect thousands of changes to occur.\nThese changes are important to track, and yet, we often use simplistic file names to do so. Many of us have experienced renaming a document or script multiple times with the disingenuous addition of “final” to the file name (like the comic above demonstrates).\nYou might think there is a better way, and you’d be right: version control. Version control provides an organized and transparent way to track changes in code and additional files. This practice was designed for software development, but is easily applicable to scientific programming.\nThere are many benefits to using a version control software including:\n\nMaintain a history of your research project’s development while keeping your workspace clean\nFacilitate collaboration and transparency when working on teams\nExplore bugs or new features without disrupting your team members’ work\nand more!\n\nThe version control system we’ll be diving into is Git, the most widely used modern version control system in the world.",
    "crumbs": [
      "Git and GitHub"
    ]
  },
  {
    "objectID": "s02_github_introduction.html#introduction-to-git-github",
    "href": "s02_github_introduction.html#introduction-to-git-github",
    "title": "Git and GitHub",
    "section": "2 Introduction to Git + GitHub",
    "text": "2 Introduction to Git + GitHub\nBefore diving into the details of Git and how to use it, let’s start with a motivating example that’s representative of the types of problems Git can help us solve.\n\n2.1 A Motivating Example\nSay, for example, you’re working on an analysis in R and you’ve got it into a state you’re pretty happy with. We’ll call this version 1:\n\n\n\nYou come into the office the following day and you have an email from your boss, “Hey, you know what this model needs?”\n\n\n\nYou’re not entirely sure what she means but you figure there’s only one thing she could be talking about: more cowbell. So you add it to the model in order to really explore the space.\nBut you’re worried about losing track of the old model so, instead of editing the code in place, you comment out the old code and put as serious a warning as you can muster in a comment above it.\n\n\n\nCommenting out code you don’t want to lose is something probably all of us have done at one point or another but it’s really hard to understand why you did this when you come back years later or you when you send your script to a colleague. Luckily, there’s a better way: Version control. Instead of commenting out the old code, we can change the code in place and tell Git to commit our change. So now we have two distinct versions of our analysis and we can always see what the previous version(s) look like.\n\n\n\nYou may have noticed something else in the diagram above: Not only can we save a new version of our analysis, we can also write as much text as we like about the change in the commit message. In addition to the commit message, Git also tracks who, when, and where the change was made.\nImagine that some time has gone by and you’ve committed a third version of your analysis, version 3, and a colleague emails with an idea: What if you used machine learning instead?\n\n\n\nMaybe you’re not so sure the idea will work out and this is where a tool like Git shines. Without a tool like Git, we might copy analysis.R to another file called analysis-ml.R which might end up having mostly the same code except for a few lines. This isn’t particularly problematic until you want to make a change to a bit of shared code and now you have to make changes in two files, if you even remember to.\nInstead, with Git, we can start a branch. Branches allow us to confidently experiment on our code, all while leaving the old code in tact and recoverable.\n\n\n\nSo you’ve been working in a branch and have made a few commits on it and your boss emails again asking you to update the model in some way. If you weren’t using a tool like Git, you might panic at this point because you’ve rewritten much of your analysis to use a different method but your boss wants change to the old method.\n\n\n\nBut with Git and branches, we can continue developing our main analysis at the same time as we are working on any experimental branches. Branches are great for experiments but also great for organizing your work generally.\n\n\n\nAfter all that hard work on the machine learning experiment, you and your colleague could decide to scrap it. It’s perfectly fine to leave branches around and switch back to the main line of development but we can also delete them to tidy up.\n\n\n\nIf, instead, you and your colleague had decided you liked the machine learning experiment, you could also merge the branch with your main development line. Merging branches is analogous to accepting a change in Word’s Track Changes feature but way more powerful and useful.\n\n\n\nA key takeaway here is that Git can drastically increase your confidence and willingness to make changes to your code and help you avoid problems down the road. Analysis rarely follows a linear path and we need a tool that respects this.\n\n\n\nFinally, imagine that, years later, your colleague asks you to make sure the model you reported in a paper you published together was actually the one you used. Another really powerful feature of Git is tags which allow us to record a particular state of our analysis with a meaningful name. In this case, we are lucky because we tagged the version of our code we used to run the analysis. Even if we continued to develop beyond commit 5 (above) after we submitted our manuscript, we can always go back and run the analysis as it was in the past.\n\nWith Git we can enhance our workflow:\n\nEliminate the need for cryptic filenames and comments to track our work.\nProvide detailed descriptions of our changes through commits, making it easier to understand the reasons behind code modifications.\nWork on multiple branches simultaneously, allowing for parallel development, and optionally merge them together.\nUse commits to access and even execute older versions of our code.\nAssign meaningful tags to specific versions of our code.\nAdditionally, Git offers a powerful distributed feature. Multiple individuals can work on the same analysis concurrently on their own computers, with the ability to merge everyone’s changes together.\n\n\n\n\n2.2 What exactly are Git and GitHub?\n\nGit:\n\nan open-source distributed version control software\ndesigned to manage the versioning and tracking of source code files and project history\noperates locally on your computer, allowing you to create repositories, and track changes\nprovides features such as committing changes, branching and merging code, reverting to previous versions, and managing project history\nworks directly with the files on your computer and does not require a network connection to perform most operations\nprimarily used through the command-line interface (CLI, e.g. Terminal), but also has various GUI tools available (e.g. RStudio IDE)\n\n\n\n\n\n\nGitHub:\n\nonline platform and service built around Git\nprovides a centralized hosting platform for Git repositories\nallows us to store, manage, and collaborate on their Git repositories in the cloud\noffers additional features on top of Git, such as a web-based interface, issue tracking, project management tools, pull requests, code review, and collaboration features\nenables easy sharing of code with others, facilitating collaboration and contribution to open source projects\nprovides a social aspect, allowing users to follow projects, star repositories, and discover new code\n\n\n\n\n\n\n\n2.3 Understanding how local working files, Git, and GitHub all work together\nIt can be a bit daunting to understand all the moving parts of the Git / GitHub life cycle (i.e. how file changes are tracked locally within repositories, then stored for safe-keeping and collaboration on remote repositories, then brought back down to a local machine(s) for continued development). It gets easier with practice, but we’ll explain (first in words, then with an illustration) at a high-level how things work:\n\n2.3.1 What is the difference between a “normal” folder vs. a Git repository\nWhether you’re a Mac or a PC user, you’ll likely have created a folder at some point in time for organizing files. Let’s pretend that we create a folder, called myFolder/, and add two files: myData.csv and myAnalysis.R. The contents of this folder are not currently version controlled – meaning, for example, that if we make some changes to myAnalysis.R that don’t quite work out, we have no way of accessing or reverting back to a previous version of myAnalysis.R (without remembering/rewriting things, of course).\nGit allows you to turn any “normal” folder, like myFolder/, into a Git repository – you’ll often see/hear this referenced as “initializing a Git repository”. When you initialize a folder on your local computer as a Git repository, a hidden .git/ folder is created within that folder (e.g. myFolder/.git/) – this .git/ folder is the Git repository. As you use Git commands to capture versions or “snapshots” of your work, those versions (and their associated metadata) get stored within the .git/ folder. This allows you to access and/or recover any previous versions of your work. If you delete .git/, you delete your project’s history.\nHere is our example folder / Git repository represented visually:\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.2 How do I actually tell Git to preserve versions of my local working files?\nGit was built as a command-line tool, meaning we can use Git commands in the command line (e.g. Terminal, Git Bash, etc.) to take “snapshots” of our local working files through time. Alternatively, RStudio provides buttons that help to easily execute these Git commands.\nGenerally, that workflow looks something like this:\n\nMake changes to a file(s) (e.g. myAnalysis.R) in your working directory.\nStage the file(s) using git add myAnalysis.R (or git add . to stage multiple changed files at once). This lets Git know that you’d like to include the file(s) in your next commit.\nCommit the file(s) using git commit -m \"a message describing my changes\". This records those changes (along with a descriptive message) as a “snapshot” or version in the local repository (i.e. the .git/ folder).\n\n\n\n2.3.3 My versioned work is on my local computer, but I want to send it to GitHub. How?\nThe last step is synchronizing the changes made to our local repository with a remote repository (oftentimes, this remote repository is stored on GitHub). The git push command is used to send local commits up to a remote repository. The git pull command is used to fetch changes from a remote repository and merge them into the local repository – pulling will become a regular part of your workflow when collaborating with others, or even when working alone but on different machines (e.g. a laptop at home and a desktop at the office).\nThe processes described in the above sections (i.e. making changes to local working files, recording “snapshots” of them to create a versioned history of changes in a local Git repository, and sending those versions from our local Git repository to a remote repository (which is oftentimes on GitHub)) is illustrated using islands, buildings, bunnies, and packages in the artwork, below:\nA basic git workflow represented as two islands, one with “local repo” and “working directory”, and another with “remote repo.” Bunnies move file boxes from the working directory to the staging area, then with Commit move them to the local repo. Bunnies in rowboats move changes from the local repo to the remote repo (labeled “PUSH”) and from the remote repo to the working directory (labeled “PULL”).\n\n\n\n\nArtwork by Allison Horst\n\n\n\n\n\n2.4 Let’s Look at a GitHub Repository\nThis screen shows the copy of a repository stored on GitHub, with its list of files, when the files and directories were last modified, and some information on who made the most recent changes.\n\n\n\nIf we drill into the “commits” for the repository, we can see the history of changes made to all of the files. Looks like kellijohnson was working on the project and fixing errors in December:\n\n\n\nAnd finally, if we drill into one of the changes made on December 20, we can see exactly what was changed in each file:\n\n\n\nTracking these changes, how they relate to released versions of software and files is exactly what Git and GitHub are good for. And we will show how they can really be effective for tracking versions of scientific code, figures, and manuscripts to accomplish a reproducible workflow.\n\n\n2.5 Git Vocabulary & Commands\nWe know the world of Git and GitHub can be daunting. Use these tables as references while you use Git and GitHub, and we encourage you to build upon this list as you become more comfortable with these tools.\nThis table contains essential terms and commands that complement intro to Git skills. They will get you far on personal and individual projects.\n\nEssential Git Commands\n\n\n\n\n\n\n\nTerm\nGit Command(s)\nDefinition\n\n\n\n\nAdd/Stage\ngit add [file]\nStaging marks a modified file in its current version to go into your next commit snapshot. You can also stage all modified files at the same time using git add .\n\n\nCommit\ngit commit\nRecords changes to the repository.\n\n\nCommit Message\ngit commit -m \"my commit message\"\nRecords changes to the repository and include a descriptive message (you should always include a commit message!).\n\n\nFetch\ngit fetch\nRetrieves changes from a remote repository but does not merge them into your local working file(s).\n\n\nPull\ngit pull\nRetrieves changes from a remote repository and merges them into your local working file(s).\n\n\nPush\ngit push\nSends local commits to a remote repository.\n\n\nStatus\ngit status\nShows the current status of the repository, including (un)staged files and branch information.\n\n\n\nThis table includes more advanced Git terms and commands that are commonly used in both individual and collaborative projects.\n\nAdvanced Git Commands\n\n\n\n\n\n\n\nTerm\nGit Command(s)\nDefinition\n\n\n\n\nBranch\ngit branch\nLists existing branches or creates a new branch.\n\n\nCheckout\ngit checkout [branch]\nSwitches to a different branch or restores files from a specific commit.\n\n\nClone\ngit clone [repository]\nCreates a local copy of a remote repository.\n\n\nDiff\ngit diff\nShows differences between files, commits, or branches.\n\n\nFork\n-\nCreates a personal copy of a repository under your GitHub account for independent development.\n\n\nLog\ngit log\nDisplays the commit history of the repository.\n\n\nMerge\ngit merge [branch]\nIntegrates changes from one branch into another branch.\n\n\nMerge Conflict\n-\nOccurs when Git cannot automatically merge changes from different branches, requiring manual resolution.\n\n\nPull Request (PR)\n-\nA request to merge changes from a branch into another branch, typically in a collaborative project.\n\n\nRebase\ngit rebase\nIntegrates changes from one branch onto another by modifying commit history.\n\n\nRemote\ngit remote\nManages remote repositories linked to the local repository.\n\n\nRepository\ngit init\nA directory where Git tracks and manages files and their versions.\n\n\nStash\ngit stash\nTemporarily saves changes that are not ready to be committed.\n\n\nTag\ngit tag\nAssigns a label or tag to a specific commit.\n\n\n\nGit has a rich set of commands and features, and there are many more terms beyond either table. Learn more by visiting the git documentation.",
    "crumbs": [
      "Git and GitHub"
    ]
  },
  {
    "objectID": "s02_github_introduction.html#exercise-1-create-a-remote-repository-on-github",
    "href": "s02_github_introduction.html#exercise-1-create-a-remote-repository-on-github",
    "title": "Git and GitHub",
    "section": "3 Exercise 1: Create a remote repository on GitHub",
    "text": "3 Exercise 1: Create a remote repository on GitHub\n\n\n\n\n\n\nSetup\n\n\n\n\nLogin to GitHub\nClick the New repository button\nName it {FIRSTNAME}_test\nAdd a short description\nCheck the box to add a README.md file\nAdd a .gitignore file using the R template\nSet the LICENSE to Apache 2.0\n\n\n\nIf you were successful, it should look something like this:\n\n\n\n\n\nYou’ve now created your first repository! It has a couple of files that GitHub created for you: README.md, LICENSE, and .gitignore.\n\n\n\n\n\n\nREADME.md files are used to share important information about your repository\n\n\n\nYou should always add a README.md to the root directory of your repository – it is a markdown file that is rendered as HTML and displayed on the landing page of your repository. This is a common place to include any pertinent information about what your repository contains, how to use it, etc.\n\n\n\n\n \n\nFor simple changes to text files, such as the README.md, you can make edits directly in the GitHub web interface.\n\n\n\n\n\n\nChallenge\n\n\n\nNavigate to the README.md file in the file listing, and edit it by clicking on the pencil icon (top right of file). This is a regular Markdown file, so you can add markdown text. Add a new level-2 header called “Purpose” and add some bullet points describing the purpose of the repo. When done, add a commit message, and hit the Commit changes button.\n\n\n\n\n\n\n\nCongratulations, you’ve now authored your first versioned commit! If you navigate back to the GitHub page for the repository, you’ll see your commit listed there, as well as the rendered README.md file.\n\n\n\n\n\nThe GitHub repository landing page provides us with lots of useful information. To start, we see:\n\nall of the files in the remote repository\nwhen each file was last edited\nthe commit message that was included with each file’s most recent commit (which is why it’s important to write good, descriptive commit messages!)\n\nAdditionally, the header above the file listing shows the most recent commit, along with its commit message, and a unique ID (assigned by Git) called a SHA. The SHA (aka hash) identifies the specific changes made, when they were made, and by who. If you click on the SHA, it will display the set of changes made in that particular commit.\n\n\n\n\n\n\nWhat should I write in my commit message?\n\n\n\nWriting effective Git commit messages is essential for creating a meaningful and helpful version history in your repository. It is crucial to avoid skipping commit messages or resorting to generic phrases like “Updates.” When it comes to following best practices, there are several guidelines to enhance the readability and maintainability of the codebase.\nHere are some guidelines for writing effective Git commit messages:\n\nBe descriptive and concise: Provide a clear and concise summary of the changes made in the commit. Aim to convey the purpose and impact of the commit in a few words.\nUse imperative tense: Write commit messages in the imperative tense, as if giving a command. For example, use “Add feature” instead of “Added feature” or “Adding feature.” This convention aligns with other Git commands and makes the messages more actionable.\nSeparate subject and body: Start with a subject line, followed by a blank line, and then provide a more detailed explanation in the body if necessary. The subject line should be a short, one-line summary, while the body can provide additional context, motivation, or details about the changes.\nLimit the subject line length: Keep the subject line within 50 characters or less. This ensures that the commit messages are easily scannable and fit well in tools like Git logs.\nCapitalize and punctuate properly: Begin the subject line with a capital letter and use proper punctuation. This adds clarity and consistency to the commit messages.\nFocus on the “what” and “why”: Explain what changes were made and why they were made. Understanding the motivation behind a commit helps future researchers and collaborators (including you!) comprehend its purpose.\nUse present tense for subject, past tense for body: Write the subject line in present tense as it represents the current state of the codebase. Use past tense in the body to describe what has been done.\nReference relevant issues: If the commit is related to a specific issue or task, include a reference to it. For example, you can mention the issue number or use keywords like “Fixes,” “Closes,” or “Resolves” followed by the issue number.",
    "crumbs": [
      "Git and GitHub"
    ]
  },
  {
    "objectID": "s02_github_introduction.html#exercise-2-clone-your-repository-and-use-git-locally-in-rstudio",
    "href": "s02_github_introduction.html#exercise-2-clone-your-repository-and-use-git-locally-in-rstudio",
    "title": "Git and GitHub",
    "section": "4 Exercise 2: clone your repository and use Git locally in RStudio",
    "text": "4 Exercise 2: clone your repository and use Git locally in RStudio\nCurrently, our repository just exists on GitHub as a remote repository. It’s easy enough to make changes to things like our README.md file (as demonstrated above), from the web browser, but that becomes a lot harder (and discouraged) for scripts and other code files. In this exercise, we’ll bring a copy of this remote repository down to our local computer (aka clone this repository) so that we can work comfortably in RStudio.\n\n\n\n\n\n\nAn important distinction\n\n\n\nWe refer to the remote copy of the repository that is on GitHub as the origin repository (the one that we cloned from), and the copy on our local computer as the local repository.\n\n\nStart by clicking the green Code button (top right of your file listing) and copying the URL to your clipboard (this URL represents the repository location):\n\n\n\n\n\n\n\nRStudio makes working with Git and version controlled files easy – to do so, you’ll need to be working within an R project folder. The following steps will look similar to those you followed when first creating an R Project, with a slight difference. Follow the instructions in the Setup box below to clone your remote repository to your local computer in RStudio:\n\n\n\n\n\n\nSetup\n\n\n\n\nClick File &gt; New Project\nSelect Version Control and paste the remote repository URL (which should be copied to your clipboard) in the Repository URL field\nPress Tab, which will auto-fill the Project directory name field with the same name as that of your remote repo – while you can name the local copy of the repository anything, it’s typical (and highly recommended) to use the same name as the GitHub repository to maintain the correspondence\n\n\n\n\n\n\n\n\n\nOnce you click Create Project, a new RStudio window will open with all of the files from the remote repository copied locally. Depending on how your version of RStudio is configured, the location and size of the panes may differ, but they should all be present – you should see a Git tab, as well as the Files tab, where you can view all of the files copied from the remote repo to this local repo.\n\n\n\n\nYou’ll note that there is one new file sam_test.Rproj, and three files that we created earlier on GitHub (.gitignore, LICENSE, and README.md).\nIn the Git tab, you’ll note that the one new file, sam_test.Rproj, is listed. This Git tab is the status pane that shows the current modification status of all of the files in the repository. Here, we see sam_test.Rproj is preceded by a ?? symbol to indicate that the file is currently untracked by Git. This means that we have not yet committed this file using Git (i.e. Git knows nothing about the file; hang tight, we’ll commit this file soon so that it’s tracked by Git). As you make version control decisions in RStudio, these icons will change to reflect the current version status of each of the files.\nInspect the history. Click on the History button in the Git tab to show the log of changes that have occurred – these changes will be identical to what we viewed on GitHub. By clicking on each row of the history, you can see exactly what was added and changed in each of the two commits in this repository.\n\n\n\n\n\n\n\n\nChallenge\n\n\n\n\nMake a change to the README.md file – this time from RStudio – then commit the README.md change\nAdd a new section to your README.md called “Creator” using a level-2 header. Under it include some information about yourself. Bonus: Add some contact information and link your email using Markdown syntax.\n\n\n\nOnce you save, you’ll immediately see the README.md file show up in the Git tab, marked as a modification. Select the file in the Git tab, and click Diff to see the changes that you saved (but which are not yet committed to your local repository). Newly made changes are highlighted in green.\n\n\n\n\nCommit the changes. To commit the changes you made to the README.md file using RStudio’s GUI (Graphical User Interface), rather than the command line:\n\nStage (aka add) README.md by clicking the check box next to the file name – this tells Git which changes you want included in the commit and is analogous to using the git command, git add README.md, in the command line\nCommit README.md by clicking the Commit button and providing a descriptive commit message in the dialog box. Press the Commit button once you’re satisfied with your message. This is analogous to using the git command, git commit -m \"my commit message\", in the command line.\n\n\nA few notes about our local repository’s state:\n\nWe still have a file, sam_test.Rproj, that is listed as untracked (denoted by ?? in the Git tab).\nYou should see a message at the top of the Git tab that says, Your branch is ahead of ‘origin/main’ by 1 commit., which tells us that we have 1 commit in the local repository, but that commit has not yet been pushed up to the origin repository (aka remote repository on GitHub).\n\nCommit the remaining project file by staging/adding and committing it with an informative commit message.\n\nWhen finished, you’ll see that no changes remain in the Git tab, and the repository is clean.\nInspect the history. Note that under Changes, the message now says:\nYour branch is ahead of ‘origin/main’ by 2 commits.\nThese are the two commits that we just made, but have not yet been pushed to GitHub.\nClick on the History button to see a total of four commits in the local repository (the two we made directly to GitHub via the web browser and the two we made in RStudio).\nPush these changes to GitHub. Now that we’ve made and committed changes locally, we can push those changes to GitHub using the Push button. This sends your changes to the remote repository (on GitHub) leaving your repository in a totally clean and synchronized state (meaning your local repository and remote repository should look the same).\n\n\n\n\n\n\nIf you are prompted to provide your GitHub username and password when Pushing…\n\n\n\nit’s a good indicator that you did not set your GitHub Personal Access Token (PAT) correctly. You can redo the steps outlined in the GitHub Authentication section to (re)set your PAT, then Push again.\n\n\n\n &lt;––&gt;\n\nIf you look at the History pane again, you’ll notice that the labels next to the most recent commit indicate that both the local repository (HEAD) and the remote repository (origin/HEAD) are pointing at the same version in the history. If we look at the commit history on GitHub, all the commits will be shown there as well.\n\n\n\n4.1 Defining Merge Method\n\n\n\n\n\n\nSome Git configuration to surpress warning messages\n\n\n\nGit version 2.27 includes a new feature that allows users to specify the default method for integrating changes from a remote repository into a local repository, without receiving a warning (this warning is informative, but can get annoying). To suppress this warning for this repository only we need to configure Git by running this line of code in the Terminal:\n\ngit config pull.rebase false\n\npull.rebase false is a default strategy for pulling where Git will first try to auto-merge the files. If auto-merging is not possible, it will indicate a merge conflict (more on resolving merge conflicts in Collaborating with Git and GitHub).\nNote: Unlike when we first configured Git, we do not include the --global flag here (e.g. git config --global pull.rebase false). This sets this default strategy for this repository only (rather than globally for all your repositories). We do this because your chosen/default method of grabbing changes from a remote repository (e.g. pulling vs. rebasing) may change depending on collaborator/workflow preference.",
    "crumbs": [
      "Git and GitHub"
    ]
  },
  {
    "objectID": "s02_github_introduction.html#exercise-3-setting-up-git-on-an-existing-project",
    "href": "s02_github_introduction.html#exercise-3-setting-up-git-on-an-existing-project",
    "title": "Git and GitHub",
    "section": "5 Exercise 3: Setting up Git on an existing project",
    "text": "5 Exercise 3: Setting up Git on an existing project\nThere are a number of different workflows for creating version-controlled repositories that are stored on GitHub. We started with Exercise 1 and Exercise 2 using one common approach: creating a remote repository on GitHub first, then cloning that repository to your local computer (you used your {FIRSTNAME}_test repo).\nHowever, you may find yourself in the situation where you have an existing directory (i.e. a “normal” folder) of code that you want to make a Git repository out of, and then send it to GitHub. In this last exercise, we will practice this workflow using your training_{USERNAME} project.\nFirst, switch to your training_{USERNAME} project using the RStudio project dropdown menu. The project drop down menu is in the upper right corner of your RStudio pane. Click the drop down next to your project name ({FIRSTNAME}_test), and then select the training_{USERNAME} project from the RECENT PROJECTS list.\nThere are a few approaches for turning an existing project folder into a Git repository, then sending it to GitHub – if you’re an R-user, the simplest way is to use the {usethis} package, which is built to automate tasks involved with project setup and development. However, you can also initialize a local git repository and set the remote repository from the command line (a language-agnostic workflow). Steps for both approaches are included below (demonstrated using your training_{USERNAME} project):\n\nUsing R & {usethis}Using the command line\n\n\n\nInstall the {usethis} package (if you haven’t done so already) by running the following in your Console:\n\n\ninstall.packages(\"usethis\")\n\n\nInitialize training_{USERNAME} as a Git repository by running usethis::use_git() in the Console. Choose yes when asked if it’s okay to commit any uncommitted files. Choose yes again if asked to restart R. Once complete, you should see the Git tab appear in your top left pane in RStudio and a .gitignore file appear in your Files tab.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.gitignore files allow you to specify which files/folders you don’t want Git to track\n\n\n\nA .gitignore file is automatically created in the root directory of your project when you initialize it as a Git repository. You’ll notice that there are already some R / R Project-specific files that have been added by default.\nWhy is this useful? For many reasons, but possibly the greatest use-case is adding large files (GitHub has a file size limit of 2 GB) or files with sensitive information (e.g. keys, tokens) that you don’t want to accidentally push to GitHub.\nHow do I do this? Let’s say I create a file with sensitive information that I don’t want to push to GitHub. I can add a line to my .gitignore file:\n\n# added by default when I initalized my RProj as a Git Repository\n.Rproj.user\n.Rhistory\n.Rdata\n.httr-oauth\n.DS_Store\n.quarto\n\n# add file so that it doesn't get pushed to the remote repo (on GitHub); \ncontains_sensitive_info.R\n\nIf this file is currently untracked by Git, it should appear in my Git tab. Once I add it to the .gitignore and save the modified .gitignore file, you should see contains_sensitive_info.R disappear from the Git tab, and a modified .gitignore (denoted by a blue M) appear. Stage/commit/push this modified .gitignore file.\n\n\n\nCreate an upstream remote repository on GitHub by running usethis::use_github() in the Console. Your web browser should open up to your new GitHub repository, with the same name as your local Git repo/R Project.\n\n\n\n\n\n\n\n\n\n\n\nEnsure that your default branch is named main rather than master by:\n\nrunning git branch in the Terminal to list all your branches (you should currently only have one, which is your default)\nif it’s named master, run the following line in the Console to update it\n\n\n\nusethis::git_default_branch_rename(from = \"master\", to = \"main\")\n\nYou can verify that your update worked by running git branch once more in the Terminal.\n\n\n\n\n\n\nWhy are we doing this?\n\n\n\nThe racist “master” terminology for git branches motivates us to update our default branch to “main” instead.\nThere is a push across platforms and software to update this historical default branch name from master to main. GitHub has already done so – you may have noticed that creating a remote repository first (like we did in Exercises 1 & 2) results in a default branch named main. Depending on your version of Git, however, you may need to set update the name manually when creating a local git repository first (as we’re doing here).\n\n\n\nYou’re now ready to edit, stage/add, commit, and push files to GitHub as practiced earlier!\n\n\n\n\n\n\n\nChallenge: add a README.md file to training_{USERNAME}\n\n\n\nGitHub provides a button on your repo’s landing page for quickly adding a README.md file. Click the Add a README button and use markdown syntax to create a README.md. Commit the changes to your repository.\nGo to your local repository (in RStudio) and pull the changes you made.\n\n\n\n\nWhile we’ll be using the RStudio Terminal here, you can use any command-line interface (e.g. Mac Terminal, Git Bash, etc.) that allows for git interactions (if you plan to use a command-line interface that is not the RStudio Terminal, make sure to navigate to your project directory (e.g. using cd file/path/to/project/directory) before initializing your repository.\n\nInitialize training_{USERNAME} as a Git repository by running git init in the Terminal. You should get a message that says something like:\n\n\nInitialized empty Git repository in /home/username/training_username/.git/\n\n\n\n\n\n\n\nYou may have to quit and reopen your RStudio session on the server for the Git tab to appear\n\n\n\nYou’ll likely need to help included-crab along in recognizing that this R Project has been initialized as a git repository – click Session &gt; Quit Session… &gt; New Session &gt; choose training_{USERNAME} to reopen your project.\n\n\nOnce complete, you should see the Git tab appear in your top left pane in RStudio and a .gitignore file appear in your Files tab.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.gitignore files allow you to specify which files/folders you don’t want Git to track\n\n\n\nA .gitignore file is automatically created in the root directory of your project when you initialize it as a Git repository. You’ll notice that there are already some R / R Project-specific files that have been added by default.\nWhy is this useful? For many reasons, but possibly the greatest use-case is adding large files (GitHub has a file size limit of 2 GB) or files with sensitive information (e.g. keys, tokens) that you don’t want to accidentally push to GitHub.\nHow do I do this? Let’s say I create a file with sensitive information that I don’t want to push to GitHub. I can add a line to my .gitignore file:\n\n# added by default when I initalized my RProj as a Git Repository\n.Rproj.user\n.Rhistory\n.Rdata\n.httr-oauth\n.DS_Store\n.quarto\n\n# add file so that it doesn't get pushed to the remote repo (on GitHub); \ncontains_sensitive_info.R\n\nIf this file is currently untracked by Git, it should appear in my Git tab. Once I add it to the .gitignore and save the modified .gitignore file, you should see contains_sensitive_info.R disappear from the Git tab, and a modified .gitignore (denoted by a blue M) appear. Stage/commit/push this modified .gitignore file.\n\n\n\nEnsure that your default branch is named main rather than master by:\n\nrunning git branch in the Terminal to list all your branches (you should currently only have one, which is your default)\nif it’s named master, run the following line in the Terminal to update it\n\n\n\n# for Git version 2.28+ (check by running `git --version`)\n# this sets the default branch name to `main` for any new repos moving forward\ngit config --global init.defaultBranch main\n\n# for older versions of Git\n# this sets the default branch name to `main` ONLY for this repo \ngit branch -m master main\n\nYou can verify that your update worked by running git branch once more in the Terminal.\n\n\n\n\n\n\nWhy are we doing this?\n\n\n\nThe racist “master” terminology for git branches motivates us to update our default branch to “main” instead.\nThere is a push across platforms and software to update this historical default branch name from master to main. GitHub has already done so – you may have noticed that creating a remote repository first (like we did in Exercises 1 & 2) results in a default branch named main. Depending on your version of Git, however, you may need to set update the name manually when creating a local git repository first (as we’re doing here).\n\n\n\nStage/Add your files. It’s helpful to first run git status to check the state of your local repository (particularly if you aren’t using RStudio / have access to a GUI with a Git tab-esque feature) – this will tell you which files have been modified or are untracked and that are currently unstaged (in red). What appears here should look just like what appears in the Git tab:\n\n\n\n\n\n\n\n\n\n\nRun git add . in the Terminal to stage all files at once (or git add {FILENAME} to stage individual files). Running git status again will show you which files have been staged (in green). You may have to refresh your Git tab to see the change in state reflected in the GUI.\n\n\n\n\n\n\n\n\n\n\nCommit your files by running git commit -m \"an informative commit message\" in the Terminal. Refreshing your Git tab will cause them to disappear (just as they do when you commit using RStudio’s GUI buttons). You can run git log in the Terminal to see a history of your past commits (currently, we only have this one).\n\n\n\n\n\n\n\n\n\n\n\nCreate an empty remote repository by logging into GitHub and creating a new repository, following the same steps as in Exercise 1. IMPORTANTLY, DO NOT initialize your remote repo with a README license, or .gitignore file – doing so now can lead to merge conflicts. We can add them after our local and remote repos are linked. Name your remote repository the same as your local repository (i.e. training_{USERNAME}).\nLink your remote (GitHub) repository to your local Git repository. Your empty GitHub repo conveniently includes instructions for doing so. Copy the code under push an existing repository from the command line to your clipboard, paste into your RStudio Terminal, and press return/enter.\n\n\n\n\n\n\n\n\n\n\nThese commands do three things:\n\nAdds the GitHub repository as the remote repository (i.e. links your local repo to the remote repo)\nRenames the default branch to main\nPushes the main branch to the remote GitHub repository\n\nHead back to your browser and refresh your GitHub repository page to see your files appear!\n\nYou’re now ready to edit, stage/add, commit, and push files to GitHub as practiced earlier!\n\n\n\n\n\n\n\nChallenge: add a README.md file to training_{USERNAME}\n\n\n\nGitHub provides a button on your repo’s landing page for quickly adding a README.md file. Click the Add a README button and use markdown syntax to create a README.md. Commit the changes to your repository.\nGo to your local repository (in RStudio) and pull the changes you made.",
    "crumbs": [
      "Git and GitHub"
    ]
  },
  {
    "objectID": "s02_github_introduction.html#go-further-with-git",
    "href": "s02_github_introduction.html#go-further-with-git",
    "title": "Git and GitHub",
    "section": "6 Go further with Git",
    "text": "6 Go further with Git\nThere’s a lot we haven’t covered in this brief tutorial. There are some great and much longer tutorials that cover advanced topics, such as:\n\nUsing Git on the command line\nResolving conflicts\nBranching and merging\nPull requests versus direct contributions for collaboration\nUsing .gitignore to protect sensitive data\nGitHub Issues - how to use them for project management and collaboration\n\nand much, much more.",
    "crumbs": [
      "Git and GitHub"
    ]
  },
  {
    "objectID": "s02_github_introduction.html#git-resources",
    "href": "s02_github_introduction.html#git-resources",
    "title": "Git and GitHub",
    "section": "7 Git resources",
    "text": "7 Git resources\n\nPro Git Book\nHappy Git and GitHub for the useR\nGitHub Documentation\nLearn Git Branching is an interactive tool to learn Git on the command line\nSoftware Carpentry Version Control with Git\nBitbucket’s tutorials on Git Workflows",
    "crumbs": [
      "Git and GitHub"
    ]
  }
]